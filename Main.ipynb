{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[âœ“] Using device: cuda\n",
      "Found existing tokenizer model: bpe_tokenizer_v1.model\n",
      "Tokenizer loaded. Vocab size: 10000. Special IDs: UNK=0, BOS=1, EOS=2, PAD=3\n",
      "Using Padding Token ID: 3\n",
      "Effective vocabulary size: 10000\n",
      "\n",
      "Loading and tokenizing datasets...\n",
      "Loaded 39557 text entries from train.jsonl (out of 39557 lines). Total combined length: 14870901 characters\n",
      "Tokenized into 3757733 tokens.\n",
      "Loaded 9890 text entries from test.jsonl (out of 9890 lines). Total combined length: 3733785 characters\n",
      "Tokenized into 943202 tokens.\n",
      "\n",
      "Building sequences...\n",
      "Number of training sequences created: 3757605\n",
      "Number of validation sequences created: 943074\n",
      "\n",
      "Creating Dataset objects and DataLoaders...\n",
      "Train dataset size: 3757605 samples\n",
      "Validation dataset size: 943074 samples\n",
      "\n",
      "Initializing models...\n",
      "\n",
      "===== Processing Model: Transformer =====\n",
      "Model: Transformer, Trainable Parameters: 5,790,224\n",
      "--- Starting Training for Transformer ---\n",
      "Epoch 01/30 | LR: 0.000300 | Train Loss: 4.6639 | Val Loss: 4.6134 | Duration: 3574.98s\n",
      "  New best validation loss: 4.6134. Saving model state.\n",
      "Epoch 02/30 | LR: 0.000300 | Train Loss: 4.4341 | Val Loss: 4.5499 | Duration: 3598.76s\n",
      "  New best validation loss: 4.5499. Saving model state.\n",
      "Epoch 03/30 | LR: 0.000300 | Train Loss: 4.3584 | Val Loss: 4.5071 | Duration: 3597.02s\n",
      "  New best validation loss: 4.5071. Saving model state.\n",
      "Epoch 04/30 | LR: 0.000300 | Train Loss: 4.3043 | Val Loss: 4.4731 | Duration: 3567.79s\n",
      "  New best validation loss: 4.4731. Saving model state.\n",
      "Epoch 05/30 | LR: 0.000300 | Train Loss: 4.2574 | Val Loss: 4.4469 | Duration: 3534.85s\n",
      "  New best validation loss: 4.4469. Saving model state.\n",
      "Epoch 06/30 | LR: 0.000300 | Train Loss: 4.2117 | Val Loss: 4.4078 | Duration: 3520.28s\n",
      "  New best validation loss: 4.4078. Saving model state.\n",
      "Epoch 07/30 | LR: 0.000300 | Train Loss: 4.1636 | Val Loss: 4.3695 | Duration: 3589.21s\n",
      "  New best validation loss: 4.3695. Saving model state.\n",
      "Epoch 08/30 | LR: 0.000300 | Train Loss: 4.1119 | Val Loss: 4.3346 | Duration: 3588.16s\n",
      "  New best validation loss: 4.3346. Saving model state.\n",
      "Epoch 09/30 | LR: 0.000300 | Train Loss: 4.0607 | Val Loss: 4.3081 | Duration: 3477.81s\n",
      "  New best validation loss: 4.3081. Saving model state.\n",
      "Epoch 10/30 | LR: 0.000300 | Train Loss: 4.0165 | Val Loss: 4.2955 | Duration: 3481.91s\n",
      "  New best validation loss: 4.2955. Saving model state.\n",
      "Epoch 11/30 | LR: 0.000300 | Train Loss: 3.9809 | Val Loss: 4.2834 | Duration: 3475.53s\n",
      "  New best validation loss: 4.2834. Saving model state.\n",
      "Epoch 12/30 | LR: 0.000300 | Train Loss: 3.9520 | Val Loss: 4.2751 | Duration: 3476.04s\n",
      "  New best validation loss: 4.2751. Saving model state.\n",
      "Epoch 13/30 | LR: 0.000300 | Train Loss: 3.9287 | Val Loss: 4.2698 | Duration: 3476.96s\n",
      "  New best validation loss: 4.2698. Saving model state.\n",
      "Epoch 14/30 | LR: 0.000300 | Train Loss: 3.9086 | Val Loss: 4.2634 | Duration: 3479.82s\n",
      "  New best validation loss: 4.2634. Saving model state.\n",
      "Epoch 15/30 | LR: 0.000300 | Train Loss: 3.8910 | Val Loss: 4.2585 | Duration: 3482.90s\n",
      "  New best validation loss: 4.2585. Saving model state.\n",
      "Epoch 16/30 | LR: 0.000300 | Train Loss: 3.8706 | Val Loss: 4.2548 | Duration: 3519.29s\n",
      "  New best validation loss: 4.2548. Saving model state.\n",
      "Epoch 17/30 | LR: 0.000300 | Train Loss: 3.8555 | Val Loss: 4.2445 | Duration: 3464.18s\n",
      "  New best validation loss: 4.2445. Saving model state.\n",
      "Epoch 18/30 | LR: 0.000300 | Train Loss: 3.8456 | Val Loss: 4.2472 | Duration: 1260.06s\n",
      "  Validation loss did not improve for 1 epoch(s).\n",
      "Epoch 19/30 | LR: 0.000300 | Train Loss: 3.8376 | Val Loss: 4.2432 | Duration: 1142.19s\n",
      "  New best validation loss: 4.2432. Saving model state.\n",
      "Epoch 20/30 | LR: 0.000300 | Train Loss: 3.8298 | Val Loss: 4.2398 | Duration: 1102.76s\n",
      "  New best validation loss: 4.2398. Saving model state.\n",
      "Epoch 21/30 | LR: 0.000300 | Train Loss: 3.8223 | Val Loss: 4.2363 | Duration: 1108.49s\n",
      "  New best validation loss: 4.2363. Saving model state.\n",
      "Epoch 22/30 | LR: 0.000300 | Train Loss: 3.8164 | Val Loss: 4.2336 | Duration: 1108.25s\n",
      "  New best validation loss: 4.2336. Saving model state.\n",
      "Epoch 23/30 | LR: 0.000300 | Train Loss: 3.8115 | Val Loss: 4.2370 | Duration: 1104.14s\n",
      "  Validation loss did not improve for 1 epoch(s).\n",
      "Epoch 24/30 | LR: 0.000300 | Train Loss: 3.8073 | Val Loss: 4.2331 | Duration: 1102.69s\n",
      "  New best validation loss: 4.2331. Saving model state.\n",
      "Epoch 25/30 | LR: 0.000300 | Train Loss: 3.8033 | Val Loss: 4.2320 | Duration: 1103.33s\n",
      "  New best validation loss: 4.2320. Saving model state.\n",
      "Epoch 26/30 | LR: 0.000300 | Train Loss: 3.8000 | Val Loss: 4.2320 | Duration: 1102.51s\n",
      "  Validation loss did not improve for 1 epoch(s).\n",
      "Epoch 27/30 | LR: 0.000300 | Train Loss: 3.7972 | Val Loss: 4.2343 | Duration: 1104.51s\n",
      "  Validation loss did not improve for 2 epoch(s).\n",
      "Epoch 28/30 | LR: 0.000300 | Train Loss: 3.7947 | Val Loss: 4.2329 | Duration: 1102.92s\n",
      "  Validation loss did not improve for 3 epoch(s).\n",
      "Epoch 29/30 | LR: 0.000150 | Train Loss: 3.7763 | Val Loss: 4.2289 | Duration: 1276.59s\n",
      "  New best validation loss: 4.2289. Saving model state.\n",
      "Epoch 30/30 | LR: 0.000150 | Train Loss: 3.7739 | Val Loss: 4.2283 | Duration: 2386.39s\n",
      "  New best validation loss: 4.2283. Saving model state.\n",
      "--- Finished Training for Transformer ---\n",
      "Total Training Time: 75910.49 seconds\n",
      "Loss curve saved as Transformer_loss_curve.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Final Transformer Model on Validation Set ---\n",
      "Calculating BLEU score on 50 validation samples...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (136) must match the size of tensor b (128) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1440\u001b[39m\n\u001b[32m   1437\u001b[39m \u001b[38;5;66;03m# --- Script Entry Point ---\u001b[39;00m\n\u001b[32m   1438\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1439\u001b[39m     \u001b[38;5;66;03m# Execute the main function when the script is run directly.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1440\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1311\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1306\u001b[39m reference_text = sp.decode(sample_target_tokens.tolist()) \u001b[38;5;66;03m# The ground truth completion/next sequence.\u001b[39;00m\n\u001b[32m   1308\u001b[39m \u001b[38;5;66;03m# Generate text using the trained model.\u001b[39;00m\n\u001b[32m   1309\u001b[39m \u001b[38;5;66;03m# Use a moderate temperature (e.g., 0.7) for generation, as greedy decoding (temp~0)\u001b[39;00m\n\u001b[32m   1310\u001b[39m \u001b[38;5;66;03m# might produce repetitive text, potentially lowering BLEU.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1311\u001b[39m generated_text = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43msp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.7\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1313\u001b[39m \u001b[38;5;66;03m# Note: The generated text includes the prompt. The reference_text corresponds to the target sequence (shifted input).\u001b[39;00m\n\u001b[32m   1314\u001b[39m \u001b[38;5;66;03m# For a fairer comparison, one might extract only the generated part after the prompt,\u001b[39;00m\n\u001b[32m   1315\u001b[39m \u001b[38;5;66;03m# but this simple approach compares the full generated sequence against the target sequence.\u001b[39;00m\n\u001b[32m   1316\u001b[39m bleu_score_sample = compute_bleu(reference_text, generated_text)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 682\u001b[39m, in \u001b[36mTransformerLanguageModel.prompt\u001b[39m\u001b[34m(self, tokenizer, prompt_text, max_length, temperature)\u001b[39m\n\u001b[32m    680\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\" Convenience method to generate text using this model. \"\"\"\u001b[39;00m\n\u001b[32m    681\u001b[39m \u001b[38;5;66;03m# The forward pass already incorporates the causal mask, so generate_text works correctly.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m682\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgenerate_text\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 418\u001b[39m, in \u001b[36mgenerate_text\u001b[39m\u001b[34m(model, tokenizer, prompt_text, max_length, temperature)\u001b[39m\n\u001b[32m    413\u001b[39m input_ids = torch.tensor([generated], dtype=torch.long, device=model_device)\n\u001b[32m    415\u001b[39m \u001b[38;5;66;03m# --- Model Forward Pass ---\u001b[39;00m\n\u001b[32m    416\u001b[39m \u001b[38;5;66;03m# Get logits from the model.\u001b[39;00m\n\u001b[32m    417\u001b[39m \u001b[38;5;66;03m# Shape: [batch_size=1, sequence_length, vocab_size]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[38;5;66;03m# --- Get Logits for Next Token ---\u001b[39;00m\n\u001b[32m    421\u001b[39m \u001b[38;5;66;03m# We only need the logits for the very last token position to predict the next token.\u001b[39;00m\n\u001b[32m    422\u001b[39m \u001b[38;5;66;03m# Shape: [vocab_size]\u001b[39;00m\n\u001b[32m    423\u001b[39m next_logits = logits[\u001b[32m0\u001b[39m, -\u001b[32m1\u001b[39m, :]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/olojo/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/olojo/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 664\u001b[39m, in \u001b[36mTransformerLanguageModel.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    662\u001b[39m embeds = \u001b[38;5;28mself\u001b[39m.embedding(x) * math.sqrt(\u001b[38;5;28mself\u001b[39m.embed_dim)\n\u001b[32m    663\u001b[39m \u001b[38;5;66;03m# Add positional encodings. Shape remains [batch, seq_len, embed_dim].\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m664\u001b[39m encoded = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpos_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    666\u001b[39m \u001b[38;5;66;03m# --- Transformer Encoder ---\u001b[39;00m\n\u001b[32m    667\u001b[39m \u001b[38;5;66;03m# Pass the encoded sequence through the Transformer encoder layers.\u001b[39;00m\n\u001b[32m    668\u001b[39m \u001b[38;5;66;03m# The `mask` argument ensures causal attention.\u001b[39;00m\n\u001b[32m    669\u001b[39m \u001b[38;5;66;03m# Input shape (due to batch_first=True): [batch, seq_len, embed_dim]\u001b[39;00m\n\u001b[32m    670\u001b[39m \u001b[38;5;66;03m# Output shape: [batch, seq_len, embed_dim]\u001b[39;00m\n\u001b[32m    671\u001b[39m transformer_out = \u001b[38;5;28mself\u001b[39m.transformer_encoder(encoded, mask=current_mask)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/olojo/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/olojo/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 130\u001b[39m, in \u001b[36mPositionalEncoding.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    117\u001b[39m \u001b[33;03mAdds positional encoding to the input tensor.\u001b[39;00m\n\u001b[32m    118\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    125\u001b[39m \u001b[33;03m            Shape: [batch_size, seq_length, embed_dim].\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;66;03m# Add positional encoding to the input embeddings.\u001b[39;00m\n\u001b[32m    128\u001b[39m \u001b[38;5;66;03m# Slice precomputed encodings 'pos_enc' to match the input sequence length (x.size(1)).\u001b[39;00m\n\u001b[32m    129\u001b[39m \u001b[38;5;66;03m# Shape: [batch_size, seq_length, embed_dim] + [1, seq_length, embed_dim] -> [batch_size, seq_length, embed_dim]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m x = \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpos_enc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[38;5;66;03m# Apply dropout for regularization.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dropout(x)\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (136) must match the size of tensor b (128) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Foundational AI Project 2 â€“ Language Modeling with RNNs, LSTMs, and Transformer (Graduate Version)\n",
    "\n",
    "This script trains three language models (RNN, LSTM, Transformer) for text generation.\n",
    "It uses a SentencePiece BPE tokenizer (vocab size=10000) to tokenize text from JSONL files,\n",
    "builds fixed-length sequences via a sliding window approach, and trains the models\n",
    "using early stopping with a ReduceLROnPlateau learning rate scheduler.\n",
    "Evaluation metrics include perplexity (exp(cross-entropy loss)), token accuracy,\n",
    "and BLEU score (computed with nltk on a sample). Sample outputs and loss curves with detailed plots\n",
    "are generated, and model performance is compared.\n",
    "Graduate-level requirements such as temperature-based decoding are supported in the prompt methods.\n",
    "\"\"\"\n",
    "\n",
    "# Standard library imports\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Third-party library imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau # Learning rate scheduler that reduces LR when a metric plateaus\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sentencepiece as spm  # For BPE tokenization\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction # BLEU score computation with smoothing\n",
    "\n",
    "# --- NLTK Data Check ---\n",
    "# Ensure the 'punkt' tokenizer data (used by nltk.word_tokenize for BLEU) is available.\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except nltk.downloader.DownloadError:\n",
    "    print(\"Downloading NLTK 'punkt' tokenizer data...\")\n",
    "    nltk.download('punkt', quiet=True) # Download quietly\n",
    "\n",
    "# --- Reproducibility ---\n",
    "# Set random seeds for Python, NumPy, and PyTorch to ensure reproducible results.\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "# Ensure reproducibility on CUDA if available (can slightly slow down computation)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# --- Device Selection ---\n",
    "# Select the appropriate computation device (GPU > MPS > CPU).\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.manual_seed_all(seed) # Set seed for all GPUs\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    # Check if MPS (Apple Silicon GPU) is available and functional.\n",
    "    try:\n",
    "        # Perform a simple tensor operation on MPS to verify usability.\n",
    "        torch.ones(1, device=\"mps\")\n",
    "        device = torch.device(\"mps\")\n",
    "    except Exception:\n",
    "        # Fallback to CPU if MPS check fails.\n",
    "        print(\"MPS device found but may not be usable. Falling back to CPU.\")\n",
    "        device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"[âœ“] Using device: {device}\")\n",
    "\n",
    "###############################################################################\n",
    "# Positional Encoding Module (for Transformer)\n",
    "###############################################################################\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Injects positional information into token embeddings using sinusoidal functions.\n",
    "    This allows the Transformer model, which lacks inherent sequence order awareness,\n",
    "    to utilize token position information. Based on 'Attention is All You Need'.\n",
    "\n",
    "    Args:\n",
    "        embed_dim (int): The embedding dimension (d_model).\n",
    "        max_len (int): The maximum sequence length for which to precompute encodings.\n",
    "                       Should be at least as large as the longest sequence length.\n",
    "        dropout (float): Dropout rate applied after adding positional encodings.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim: int, max_len: int = 512, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Create a matrix for positional encodings: [max_len, embed_dim]\n",
    "        pos_enc = torch.zeros(max_len, embed_dim)\n",
    "\n",
    "        # Create position indices: [max_len, 1] (tensor([[0.], [1.], ..., [max_len-1]]))\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "        # Calculate the division term for the frequencies.\n",
    "        # Formula: 1 / (10000^(2i / embed_dim))\n",
    "        # Use log space for numerical stability: exp(-log(10000) * (2i / embed_dim))\n",
    "        div_term = torch.exp(torch.arange(0, embed_dim, 2, dtype=torch.float) * -(math.log(10000.0) / embed_dim))\n",
    "\n",
    "        # Calculate sinusoidal encodings:\n",
    "        # Even indices (0, 2, 4, ...): PE(pos, 2i) = sin(pos / (10000^(2i / embed_dim)))\n",
    "        pos_enc[:, 0::2] = torch.sin(position * div_term)\n",
    "        # Odd indices (1, 3, 5, ...): PE(pos, 2i+1) = cos(pos / (10000^(2i / embed_dim)))\n",
    "        pos_enc[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        # Add a batch dimension: [1, max_len, embed_dim]\n",
    "        # This allows easy broadcasting when adding to batch embeddings.\n",
    "        pos_enc = pos_enc.unsqueeze(0)\n",
    "\n",
    "        # Register 'pos_enc' as a buffer. Buffers are part of the model's state_dict\n",
    "        # but are not considered model parameters (not updated by optimizer).\n",
    "        self.register_buffer(\"pos_enc\", pos_enc)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Adds positional encoding to the input tensor.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor of token embeddings.\n",
    "                        Shape: [batch_size, seq_length, embed_dim].\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Output tensor with positional information added.\n",
    "                    Shape: [batch_size, seq_length, embed_dim].\n",
    "        \"\"\"\n",
    "        # Add positional encoding to the input embeddings.\n",
    "        # Slice precomputed encodings 'pos_enc' to match the input sequence length (x.size(1)).\n",
    "        # Shape: [batch_size, seq_length, embed_dim] + [1, seq_length, embed_dim] -> [batch_size, seq_length, embed_dim]\n",
    "        x = x + self.pos_enc[:, :x.size(1)]\n",
    "\n",
    "        # Apply dropout for regularization.\n",
    "        return self.dropout(x)\n",
    "\n",
    "###############################################################################\n",
    "# Data Preparation Functions\n",
    "###############################################################################\n",
    "def train_tokenizer_if_needed(tokenizer_model_prefix: str = \"tokenizer\", vocab_size: int = 10000, training_text_file: str = \"merged_corpus.txt\") -> spm.SentencePieceProcessor:\n",
    "    \"\"\"\n",
    "    Trains a SentencePiece BPE (Byte-Pair Encoding) tokenizer on the provided text file\n",
    "    if the tokenizer model files (.model, .vocab) do not already exist.\n",
    "\n",
    "    Args:\n",
    "        tokenizer_model_prefix (str): The prefix for the output model and vocabulary files.\n",
    "        vocab_size (int): The target vocabulary size for the tokenizer.\n",
    "        training_text_file (str): The path to the plain text file used for training the tokenizer.\n",
    "\n",
    "    Returns:\n",
    "        spm.SentencePieceProcessor: An instance of the loaded SentencePiece processor.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the training text file does not exist and model files are missing.\n",
    "        Exception: If tokenizer training fails.\n",
    "    \"\"\"\n",
    "    model_path = f\"{tokenizer_model_prefix}.model\"\n",
    "    vocab_path = f\"{tokenizer_model_prefix}.vocab\"\n",
    "\n",
    "    # Check if both model and vocab files exist.\n",
    "    if not os.path.exists(model_path) or not os.path.exists(vocab_path):\n",
    "        print(f\"Tokenizer model ('{model_path}' or '{vocab_path}') not found. Training...\")\n",
    "        # Check if the training data file exists.\n",
    "        if not os.path.exists(training_text_file):\n",
    "             raise FileNotFoundError(f\"Tokenizer training file '{training_text_file}' not found. Cannot train tokenizer.\")\n",
    "\n",
    "        try:\n",
    "            # Train the SentencePiece model using the specified parameters.\n",
    "            spm.SentencePieceTrainer.train(\n",
    "                input=training_text_file,          # Path to the training text file.\n",
    "                model_prefix=tokenizer_model_prefix, # Prefix for output files (.model, .vocab).\n",
    "                vocab_size=vocab_size,             # Target size of the vocabulary.\n",
    "                model_type=\"bpe\",                  # Use Byte-Pair Encoding algorithm.\n",
    "                character_coverage=1.0,            # Try to cover all characters in the training data.\n",
    "                # Define IDs for standard special tokens. SentencePiece uses these defaults if not specified.\n",
    "                # UNK (Unknown): Represents out-of-vocabulary words.\n",
    "                # BOS (Beginning-of-Sequence): Optional start token.\n",
    "                # EOS (End-of-Sequence): Marks the end of a sentence or sequence.\n",
    "                # PAD (Padding): Used to make sequences in a batch the same length.\n",
    "                unk_id=0,       # Typically ID 0 for <unk>\n",
    "                bos_id=1,       # Typically ID 1 for <s>\n",
    "                eos_id=2,       # Typically ID 2 for </s>\n",
    "                pad_id=3        # Explicitly set PAD ID to 3. If set to -1, PAD is disabled.\n",
    "            )\n",
    "            print(\"Tokenizer training complete.\")\n",
    "        except Exception as e:\n",
    "            # Handle potential errors during training.\n",
    "            print(f\"Error training tokenizer: {e}\")\n",
    "            # Clean up potentially incomplete model/vocab files if training failed.\n",
    "            if os.path.exists(model_path): os.remove(model_path)\n",
    "            if os.path.exists(vocab_path): os.remove(vocab_path)\n",
    "            raise # Re-raise the exception after cleanup.\n",
    "    else:\n",
    "        # If model files exist, skip training.\n",
    "        print(f\"Found existing tokenizer model: {model_path}\")\n",
    "\n",
    "    # Load the trained tokenizer model from the file.\n",
    "    sp = spm.SentencePieceProcessor(model_file=model_path)\n",
    "    # Print tokenizer details for verification.\n",
    "    print(f\"Tokenizer loaded. Vocab size: {sp.vocab_size()}. Special IDs: \"\n",
    "          f\"UNK={sp.unk_id()}, BOS={sp.bos_id()}, EOS={sp.eos_id()}, PAD={sp.pad_id()}\")\n",
    "    return sp\n",
    "\n",
    "def load_and_tokenize(file_path: str, sp: spm.SentencePieceProcessor) -> list[int]:\n",
    "    \"\"\"\n",
    "    Loads text data from a JSONL file (each line is a JSON object), extracts \"prompt\"\n",
    "    and \"completion\" fields, combines them, concatenates all entries using the\n",
    "    tokenizer's EOS token as a separator, and tokenizes the entire text into a single\n",
    "    list of token IDs.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the JSONL file.\n",
    "        sp (SentencePieceProcessor): The initialized SentencePiece tokenizer instance.\n",
    "\n",
    "    Returns:\n",
    "        list[int]: A flat list of token IDs representing the tokenized content of the file.\n",
    "    \"\"\"\n",
    "    texts = [] # List to hold individual text entries (prompt + completion)\n",
    "    count = 0  # Counter for total lines processed\n",
    "\n",
    "    # Read the JSONL file line by line.\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            count += 1\n",
    "            try:\n",
    "                # Attempt to parse the line as a JSON object.\n",
    "                obj = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                # Skip lines that are not valid JSON.\n",
    "                # print(f\"Warning: Skipping invalid JSON line in {file_path} (line {count})\")\n",
    "                continue\n",
    "            # Extract \"prompt\" and \"completion\" fields, defaulting to empty strings if missing.\n",
    "            prompt = obj.get(\"prompt\", \"\")\n",
    "            completion = obj.get(\"completion\", \"\")\n",
    "            # Combine prompt and completion, stripping leading/trailing whitespace.\n",
    "            text = (prompt + \" \" + completion).strip()\n",
    "            # Add the combined text to the list if it's not empty.\n",
    "            if text:\n",
    "                texts.append(text)\n",
    "\n",
    "    # --- Determine the EOS token string for separation ---\n",
    "    eos_id = sp.eos_id() # Get the integer ID for the EOS token.\n",
    "    eos_string = \"\"      # Initialize EOS string representation.\n",
    "\n",
    "    if eos_id is not None and eos_id >= 0: # Check if a valid EOS ID exists.\n",
    "        try:\n",
    "            # Decode the EOS ID back to its string representation (e.g., \"</s>\").\n",
    "            # Need to pass it as a list to decode.\n",
    "            eos_string = sp.decode([eos_id])\n",
    "            # Handle cases where the decoded special token might be empty or unexpected.\n",
    "            # Use common default '</s>' if ID is 2 and decode is empty.\n",
    "            if not eos_string and eos_id == 2:\n",
    "                eos_string = \"</s>\"\n",
    "            # If still empty after checks, issue a warning and fallback to newline.\n",
    "            if not eos_string:\n",
    "                 print(f\"Warning: Decoded EOS token ID {eos_id} resulted in an empty string. Using newline fallback.\")\n",
    "                 eos_string = \"\\n\"\n",
    "        except Exception as e:\n",
    "             # Handle errors during decoding and fallback to newline.\n",
    "             print(f\"Warning: Could not decode EOS token ID {eos_id}. Error: {e}. Using newline fallback.\")\n",
    "             eos_string = \"\\n\"\n",
    "    else:\n",
    "        # If no EOS token ID is defined in the tokenizer, use newline as separator.\n",
    "        print(\"Warning: EOS token ID not found in tokenizer. Using newline as separator.\")\n",
    "        eos_string = \"\\n\"\n",
    "\n",
    "    # Define the separator string, adding newlines around the EOS token for clarity.\n",
    "    # Strip potential whitespace from the decoded token itself.\n",
    "    separator = f\"\\n{eos_string.strip()}\\n\"\n",
    "\n",
    "    # Join all extracted text entries into a single large string using the separator.\n",
    "    # This creates one continuous corpus for sequence building.\n",
    "    combined = separator.join(texts)\n",
    "    # --- End of EOS handling and text combination ---\n",
    "\n",
    "    print(f\"Loaded {len(texts)} text entries from {file_path} (out of {count} lines). \"\n",
    "          f\"Total combined length: {len(combined)} characters\")\n",
    "\n",
    "    # Tokenize the entire combined text into a list of integer IDs.\n",
    "    token_ids = sp.encode(combined, out_type=int)\n",
    "    print(f\"Tokenized into {len(token_ids)} tokens.\")\n",
    "    return token_ids\n",
    "\n",
    "def build_sequences(token_ids: list[int], seq_length: int) -> list[list[int]]:\n",
    "    \"\"\"\n",
    "    Creates overlapping sequences of a fixed length from a flat list of token IDs\n",
    "    using a sliding window approach. Each sequence has length `seq_length + 1`\n",
    "    to facilitate creating input/target pairs (input = seq[:-1], target = seq[1:]).\n",
    "\n",
    "    Args:\n",
    "        token_ids (list[int]): The flat list of token IDs from the tokenized corpus.\n",
    "        seq_length (int): The desired length of the *input* sequences. The generated\n",
    "                          sequences will have length `seq_length + 1`.\n",
    "\n",
    "    Returns:\n",
    "        list[list[int]]: A list of sequences, where each sequence is a list of token IDs\n",
    "                         of length `seq_length + 1`. Returns an empty list if no\n",
    "                         valid sequences can be created.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If `seq_length` is not positive.\n",
    "    \"\"\"\n",
    "    # Validate seq_length.\n",
    "    if seq_length <= 0:\n",
    "        raise ValueError(\"seq_length must be positive.\")\n",
    "    # Check if there are enough tokens to form even one sequence.\n",
    "    if len(token_ids) <= seq_length:\n",
    "         print(f\"Warning: Token list length ({len(token_ids)}) is not greater than seq_length ({seq_length}). \"\n",
    "               \"Cannot generate sequences.\")\n",
    "         return []\n",
    "\n",
    "    # Use a list comprehension for efficient sliding window creation.\n",
    "    # For each starting index `i`, take a slice of length `seq_length + 1`.\n",
    "    # Stop when the slice would go beyond the end of the `token_ids` list.\n",
    "    sequences = [token_ids[i : i + seq_length + 1] for i in range(len(token_ids) - seq_length)]\n",
    "    return sequences\n",
    "\n",
    "###############################################################################\n",
    "# Custom Dataset Class for Language Modeling\n",
    "###############################################################################\n",
    "class LanguageModelDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset for language modeling. It takes a list of token sequences\n",
    "    (each of length `seq_length + 1`) and provides input/target pairs for training.\n",
    "    Each sample retrieved by `__getitem__` is a tuple (input_tokens, target_tokens),\n",
    "    where `target_tokens` are the `input_tokens` shifted one position to the right.\n",
    "    \"\"\"\n",
    "    def __init__(self, sequences: list[list[int]], seq_length: int):\n",
    "        \"\"\"\n",
    "        Initializes the dataset.\n",
    "\n",
    "        Args:\n",
    "            sequences (list[list[int]]): A list of token sequences, where each sequence\n",
    "                                         is expected to have length `seq_length + 1`.\n",
    "            seq_length (int): The length of the input sequences (targets will also have this length).\n",
    "        \"\"\"\n",
    "        # Create input/target pairs: input = sequence[:-1], target = sequence[1:]\n",
    "        # Include a check to filter out any sequences that might not have the exact required length.\n",
    "        # This should ideally not happen if `build_sequences` is used correctly, but acts as a safeguard.\n",
    "        self.samples = [(seq[:-1], seq[1:]) for seq in sequences if len(seq) == seq_length + 1]\n",
    "\n",
    "        # Report if any sequences were filtered out due to incorrect length.\n",
    "        if len(self.samples) < len(sequences):\n",
    "             print(f\"Warning: Filtered out {len(sequences) - len(self.samples)} sequences due to \"\n",
    "                   f\"incorrect length (expected {seq_length + 1}).\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Returns the total number of samples (input/target pairs) in the dataset.\"\"\"\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Retrieves the sample (input/target pair) at the given index.\n",
    "\n",
    "        Args:\n",
    "            idx (int): The index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            tuple[torch.Tensor, torch.Tensor]: A tuple containing:\n",
    "                - input_tokens (torch.Tensor): Tensor of input token IDs (dtype=torch.long).\n",
    "                - target_tokens (torch.Tensor): Tensor of target token IDs (dtype=torch.long).\n",
    "        \"\"\"\n",
    "        inp_ids, target_ids = self.samples[idx]\n",
    "        # Convert the lists of token IDs to PyTorch tensors of type long.\n",
    "        return torch.tensor(inp_ids, dtype=torch.long), torch.tensor(target_ids, dtype=torch.long)\n",
    "\n",
    "###############################################################################\n",
    "# Text Generation Function and Model Definitions\n",
    "###############################################################################\n",
    "def generate_text(model: nn.Module,\n",
    "                  tokenizer: spm.SentencePieceProcessor,\n",
    "                  prompt_text: str,\n",
    "                  max_length: int = 128,\n",
    "                  temperature: float = 1.0) -> str:\n",
    "    \"\"\"\n",
    "    Generates text autoregressively starting from a given prompt using the provided model.\n",
    "\n",
    "    Supports temperature-based sampling for controlling randomness.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The trained language model (RNN, LSTM, or Transformer).\n",
    "        tokenizer (SentencePieceProcessor): The tokenizer used for encoding/decoding.\n",
    "        prompt_text (str): The initial text to seed the generation.\n",
    "        max_length (int): The maximum number of *new* tokens to generate after the prompt.\n",
    "        temperature (float): Controls the randomness of sampling.\n",
    "                             - temperature=0 (or close to 0): Greedy decoding (always pick the most likely token).\n",
    "                             - temperature=1.0: Standard sampling from the model's predicted probabilities.\n",
    "                             - temperature > 1.0: Increases randomness, makes less likely tokens more probable.\n",
    "                             - 0 < temperature < 1.0: Decreases randomness, favors more likely tokens.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated text, including the original prompt.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model_device = next(model.parameters()).device\n",
    "\n",
    "    # initial tokens\n",
    "    generated = tokenizer.encode(prompt_text,\n",
    "                                 out_type=int,\n",
    "                                 add_bos=False,\n",
    "                                 add_eos=False).copy()\n",
    "\n",
    "    eos_token_id = tokenizer.eos_id()\n",
    "    if eos_token_id is None or eos_token_id < 0:\n",
    "        eos_token_id = -1\n",
    "\n",
    "    # get the model's max_seq_length if it exists\n",
    "    max_allowed = getattr(model, \"max_seq_length\", None)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            # TRUNCATE here:\n",
    "            seq = generated\n",
    "            if max_allowed and len(seq) > max_allowed:\n",
    "                seq = seq[-max_allowed:]\n",
    "\n",
    "            input_ids = torch.tensor([seq], dtype=torch.long, device=model_device)\n",
    "            logits = model(input_ids)\n",
    "            next_logits = logits[0, -1, :]\n",
    "\n",
    "            if temperature < 1e-5:\n",
    "                next_token = torch.argmax(next_logits).item()\n",
    "            else:\n",
    "                probs = torch.softmax(next_logits / temperature, dim=-1)\n",
    "                next_token = torch.multinomial(probs, num_samples=1).item()\n",
    "\n",
    "            if next_token == eos_token_id:\n",
    "                break\n",
    "            generated.append(next_token)\n",
    "\n",
    "    return tokenizer.decode(generated)\n",
    "\n",
    "\n",
    "class RNNLanguageModel(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple language model based on vanilla Recurrent Neural Networks (RNNs).\n",
    "\n",
    "    Architecture:\n",
    "        1. Embedding Layer: Maps input token IDs to dense vectors.\n",
    "        2. Dropout Layer: Applied after embedding.\n",
    "        3. RNN Layer(s): Processes the sequence of embeddings.\n",
    "        4. Dropout Layer: Applied after RNN output.\n",
    "        5. Linear Layer (FC): Maps RNN hidden states to vocabulary logits.\n",
    "\n",
    "    Args:\n",
    "        vocab_size (int): Size of the vocabulary.\n",
    "        embed_dim (int): Dimension of token embeddings.\n",
    "        hidden_dim (int): Dimension of RNN hidden states.\n",
    "        num_layers (int): Number of stacked RNN layers.\n",
    "        dropout (float): Dropout probability for dropout layers.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size: int, embed_dim: int, hidden_dim: int, num_layers: int, dropout: float = 0.2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        # `batch_first=True`: Input/output tensors have shape [batch, seq, feature].\n",
    "        # Dropout is applied between RNN layers if num_layers > 1.\n",
    "        self.rnn = nn.RNN(embed_dim, hidden_dim, num_layers,\n",
    "                          batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "        # Fully connected layer to project RNN output to vocabulary size.\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        # Separate dropout layer applied after embedding and RNN output.\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Performs the forward pass of the RNN model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of token IDs. Shape: [batch_size, seq_length].\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor of logits. Shape: [batch_size, seq_length, vocab_size].\n",
    "        \"\"\"\n",
    "        # 1. Embeddings\n",
    "        # Shape: [batch_size, seq_length] -> [batch_size, seq_length, embed_dim]\n",
    "        embeds = self.dropout_layer(self.embedding(x))\n",
    "\n",
    "        # 2. RNN\n",
    "        # `output` contains hidden states for all time steps. Shape: [batch, seq_length, hidden_dim]\n",
    "        # `_` holds the final hidden state (h_n). We don't need it directly for logits.\n",
    "        output, _ = self.rnn(embeds)\n",
    "        # Apply dropout to the RNN output sequence.\n",
    "        output = self.dropout_layer(output)\n",
    "\n",
    "        # 3. Fully Connected Layer\n",
    "        # Project hidden states to vocabulary logits.\n",
    "        # Shape: [batch, seq_length, hidden_dim] -> [batch, seq_length, vocab_size]\n",
    "        logits = self.fc(output)\n",
    "        return logits\n",
    "\n",
    "    def prompt(self, tokenizer: spm.SentencePieceProcessor, prompt_text: str, max_length: int = 128, temperature: float = 1.0) -> str:\n",
    "        \"\"\" Convenience method to generate text using this model. \"\"\"\n",
    "        return generate_text(self, tokenizer, prompt_text, max_length, temperature)\n",
    "\n",
    "class LSTMLanguageModel(nn.Module):\n",
    "    \"\"\"\n",
    "    A language model based on Long Short-Term Memory (LSTM) networks.\n",
    "\n",
    "    Architecture is similar to RNNLanguageModel, but uses LSTM layers which are\n",
    "    generally better at capturing long-range dependencies.\n",
    "\n",
    "    Args:\n",
    "        vocab_size (int): Size of the vocabulary.\n",
    "        embed_dim (int): Dimension of token embeddings.\n",
    "        hidden_dim (int): Dimension of LSTM hidden and cell states.\n",
    "        num_layers (int): Number of stacked LSTM layers.\n",
    "        dropout (float): Dropout probability for dropout layers and between LSTM layers.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size: int, embed_dim: int, hidden_dim: int, num_layers: int, dropout: float = 0.2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        # `batch_first=True`: Input/output tensors have shape [batch, seq, feature].\n",
    "        # Dropout is applied between LSTM layers if num_layers > 1.\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers,\n",
    "                            batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "        # Fully connected layer to project LSTM output to vocabulary size.\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        # Separate dropout layer applied after embedding and LSTM output.\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Performs the forward pass of the LSTM model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of token IDs. Shape: [batch_size, seq_length].\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor of logits. Shape: [batch_size, seq_length, vocab_size].\n",
    "        \"\"\"\n",
    "        # 1. Embeddings\n",
    "        # Shape: [batch_size, seq_length] -> [batch_size, seq_length, embed_dim]\n",
    "        embeds = self.dropout_layer(self.embedding(x))\n",
    "\n",
    "        # 2. LSTM\n",
    "        # `output` contains hidden states for all time steps. Shape: [batch, seq_length, hidden_dim]\n",
    "        # `_` holds the final hidden state (h_n) and cell state (c_n). We don't need them directly for logits.\n",
    "        output, _ = self.lstm(embeds)\n",
    "        # Apply dropout to the LSTM output sequence.\n",
    "        output = self.dropout_layer(output)\n",
    "\n",
    "        # 3. Fully Connected Layer\n",
    "        # Project hidden states to vocabulary logits.\n",
    "        # Shape: [batch, seq_length, hidden_dim] -> [batch, seq_length, vocab_size]\n",
    "        logits = self.fc(output)\n",
    "        return logits\n",
    "\n",
    "    def prompt(self, tokenizer: spm.SentencePieceProcessor, prompt_text: str, max_length: int = 128, temperature: float = 1.0) -> str:\n",
    "        \"\"\" Convenience method to generate text using this model. \"\"\"\n",
    "        return generate_text(self, tokenizer, prompt_text, max_length, temperature)\n",
    "\n",
    "class TransformerLanguageModel(nn.Module):\n",
    "    \"\"\"\n",
    "    A language model based on the Transformer architecture (specifically, the Encoder part).\n",
    "    Uses self-attention mechanism to capture dependencies between tokens, potentially\n",
    "    handling long-range dependencies better than RNNs/LSTMs. Includes positional encoding\n",
    "    and a causal mask for autoregressive generation.\n",
    "\n",
    "    Architecture:\n",
    "        1. Embedding Layer: Maps token IDs to vectors. Embeddings are scaled.\n",
    "        2. Positional Encoding: Adds positional information to embeddings.\n",
    "        3. Transformer Encoder: Consists of multiple Transformer Encoder Layers.\n",
    "           - Each layer has Multi-Head Self-Attention and a Feed-Forward Network.\n",
    "           - A causal mask is applied to ensure autoregressive property (attend only to past tokens).\n",
    "        4. Linear Layer (FC): Maps Transformer output to vocabulary logits.\n",
    "\n",
    "    Args:\n",
    "        vocab_size (int): Size of the vocabulary.\n",
    "        embed_dim (int): Dimension of token embeddings (d_model).\n",
    "        num_heads (int): Number of attention heads in Multi-Head Self-Attention. Must divide embed_dim.\n",
    "        hidden_dim (int): Dimension of the feed-forward network inside Transformer layers.\n",
    "        num_layers (int): Number of stacked Transformer Encoder layers.\n",
    "        max_seq_length (int): Maximum sequence length the model can handle (used for causal mask).\n",
    "        dropout (float): Dropout probability used in positional encoding and Transformer layers.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size: int, embed_dim: int, num_heads: int, hidden_dim: int, num_layers: int, max_seq_length: int, dropout: float = 0.2):\n",
    "        super().__init__()\n",
    "        # Ensure embedding dimension is divisible by the number of heads.\n",
    "        assert embed_dim % num_heads == 0, \"embed_dim must be divisible by num_heads\"\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.pos_encoder = PositionalEncoding(embed_dim, max_len=max_seq_length, dropout=dropout)\n",
    "\n",
    "        # Define a single Transformer Encoder layer.\n",
    "        # `batch_first=True` ensures input/output shapes are [batch, seq, feature].\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads,\n",
    "                                                   dim_feedforward=hidden_dim, dropout=dropout,\n",
    "                                                   batch_first=True) # Crucial for shape consistency\n",
    "        # Stack multiple encoder layers.\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # Fully connected layer to project Transformer output to vocabulary size.\n",
    "        self.fc = nn.Linear(embed_dim, vocab_size)\n",
    "\n",
    "        # Store embedding dimension and max sequence length for later use.\n",
    "        self.embed_dim = embed_dim\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "        # --- Causal Mask ---\n",
    "        # Generate and register a causal (subsequent) mask. This prevents attention\n",
    "        # to future positions, which is essential for autoregressive language modeling.\n",
    "        # The mask shape will be [max_seq_length, max_seq_length].\n",
    "        self.register_buffer('causal_mask', self._generate_square_subsequent_mask(max_seq_length))\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Generates a square causal mask of size [sz, sz].\n",
    "        Masked positions (future tokens) are filled with float('-inf'),\n",
    "        unmasked positions (current and past tokens) are filled with float(0.0).\n",
    "        The Transformer layer adds this mask to the attention scores before softmax.\n",
    "        \"\"\"\n",
    "        # Create an upper triangle matrix of 1s.\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        # Fill with -inf where mask is 0 (future positions), and 0.0 where mask is 1 (current/past).\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Performs the forward pass of the Transformer model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of token IDs. Shape: [batch_size, seq_length].\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor of logits. Shape: [batch_size, seq_length, vocab_size].\n",
    "        \"\"\"\n",
    "        # Get the actual sequence length from the input batch.\n",
    "        seq_len = x.size(1)\n",
    "\n",
    "        # --- Prepare Mask ---\n",
    "        # Select the appropriate part of the precomputed causal mask for the current sequence length.\n",
    "        # The mask needs to be on the same device as the input tensor `x`.\n",
    "        # Shape required by TransformerEncoder: [seq_len, seq_len]\n",
    "        current_mask = self.causal_mask[:seq_len, :seq_len].to(x.device)\n",
    "\n",
    "        # --- Embeddings and Positional Encoding ---\n",
    "        # Convert token IDs to embeddings. Shape: [batch, seq_len] -> [batch, seq_len, embed_dim]\n",
    "        # Scale embeddings by sqrt(embed_dim) as suggested in the 'Attention is All You Need' paper.\n",
    "        embeds = self.embedding(x) * math.sqrt(self.embed_dim)\n",
    "        # Add positional encodings. Shape remains [batch, seq_len, embed_dim].\n",
    "        encoded = self.pos_encoder(embeds)\n",
    "\n",
    "        # --- Transformer Encoder ---\n",
    "        # Pass the encoded sequence through the Transformer encoder layers.\n",
    "        # The `mask` argument ensures causal attention.\n",
    "        # Input shape (due to batch_first=True): [batch, seq_len, embed_dim]\n",
    "        # Output shape: [batch, seq_len, embed_dim]\n",
    "        transformer_out = self.transformer_encoder(encoded, mask=current_mask)\n",
    "\n",
    "        # --- Fully Connected Layer ---\n",
    "        # Project Transformer output to vocabulary logits.\n",
    "        # Shape: [batch, seq_len, embed_dim] -> [batch, seq_len, vocab_size]\n",
    "        logits = self.fc(transformer_out)\n",
    "        return logits\n",
    "\n",
    "    def prompt(self, tokenizer: spm.SentencePieceProcessor, prompt_text: str, max_length: int = 128, temperature: float = 1.0) -> str:\n",
    "        \"\"\" Convenience method to generate text using this model. \"\"\"\n",
    "        # The forward pass already incorporates the causal mask, so generate_text works correctly.\n",
    "        return generate_text(self, tokenizer, prompt_text, max_length, temperature)\n",
    "\n",
    "###############################################################################\n",
    "# Training, Evaluation, and Plotting Functions\n",
    "###############################################################################\n",
    "def train_model(model: nn.Module, train_loader: DataLoader, val_loader: DataLoader, num_epochs: int,\n",
    "                criterion: nn.Module, optimizer: optim.Optimizer, scheduler: ReduceLROnPlateau,\n",
    "                device: torch.device, patience: int = 5, model_name: str = \"Model\") -> tuple[list, list, float]:\n",
    "    \"\"\"\n",
    "    Trains the language model using the provided data loaders and hyperparameters.\n",
    "    Implements mini-batch gradient descent, gradient clipping, ReduceLROnPlateau\n",
    "    learning rate scheduling, and early stopping based on validation loss.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The language model to train.\n",
    "        train_loader (DataLoader): DataLoader for the training dataset.\n",
    "        val_loader (DataLoader): DataLoader for the validation dataset.\n",
    "        num_epochs (int): The maximum number of epochs to train for.\n",
    "        criterion (nn.Module): The loss function (e.g., CrossEntropyLoss).\n",
    "        optimizer (optim.Optimizer): The optimizer (e.g., AdamW).\n",
    "        scheduler (ReduceLROnPlateau): The learning rate scheduler.\n",
    "        device (torch.device): The device (CPU/GPU) to train on.\n",
    "        patience (int): Number of epochs to wait for validation loss improvement before stopping early.\n",
    "        model_name (str): Name of the model (used for logging).\n",
    "\n",
    "    Returns:\n",
    "        tuple[list, list, float]: A tuple containing:\n",
    "            - train_losses (list): List of average training losses per epoch.\n",
    "            - val_losses (list): List of average validation losses per epoch.\n",
    "            - total_training_time (float): Total time taken for training in seconds.\n",
    "    \"\"\"\n",
    "    # Move the model to the specified device.\n",
    "    model.to(device)\n",
    "\n",
    "    # Lists to store loss values for plotting.\n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    # Variables for early stopping.\n",
    "    best_val_loss = float('inf') # Initialize with infinity; lower is better.\n",
    "    best_model_state = None      # To store the state_dict of the best model.\n",
    "    epochs_no_improve = 0        # Counter for epochs without validation loss improvement.\n",
    "\n",
    "    print(f\"--- Starting Training for {model_name} ---\")\n",
    "    total_start_time = time.time()\n",
    "\n",
    "    # --- Training Loop ---\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # --- Training Phase ---\n",
    "        model.train() # Set the model to training mode (enables dropout, etc.).\n",
    "        total_train_loss = 0.0\n",
    "        num_batches = 0\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "            # Move batch data to the target device.\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # Zero the gradients accumulated from the previous batch.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass: Get model predictions (logits).\n",
    "            # Shape: [batch, seq_length, vocab_size]\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Calculate the loss.\n",
    "            # Reshape outputs and targets for CrossEntropyLoss:\n",
    "            # Outputs: [batch * seq_length, vocab_size]\n",
    "            # Targets: [batch * seq_length]\n",
    "            loss = criterion(outputs.view(-1, outputs.size(-1)), targets.view(-1))\n",
    "\n",
    "            # Check for NaN loss, which can indicate instability.\n",
    "            if torch.isnan(loss):\n",
    "                print(f\"Warning: NaN loss detected at epoch {epoch}, batch {batch_idx}. Skipping batch update.\")\n",
    "                # Consider logging more details or stopping if NaNs persist.\n",
    "                continue # Skip backward pass and optimizer step for this batch.\n",
    "\n",
    "            # Backward pass: Compute gradients of the loss w.r.t. model parameters.\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient Clipping: Prevent exploding gradients by clipping the norm of gradients.\n",
    "            # Helps stabilize training, especially with RNNs/LSTMs.\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "            # Update model parameters using the computed gradients.\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate loss for averaging later.\n",
    "            total_train_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "            # Optional: Log progress within an epoch.\n",
    "            # if (batch_idx + 1) % 100 == 0:\n",
    "            #     print(f\"  Epoch {epoch}/{num_epochs}, Batch {batch_idx+1}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "        # Calculate average training loss for the epoch.\n",
    "        if num_batches == 0:\n",
    "             print(\"Warning: No batches processed in training epoch {epoch}. Check data loader.\")\n",
    "             avg_train_loss = 0.0\n",
    "        else:\n",
    "            avg_train_loss = total_train_loss / num_batches\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # --- Validation Phase ---\n",
    "        model.eval() # Set the model to evaluation mode (disables dropout, etc.).\n",
    "        total_val_loss = 0.0\n",
    "        num_val_batches = 0\n",
    "        with torch.no_grad(): # Disable gradient calculations during validation.\n",
    "            for inputs, targets in val_loader:\n",
    "                # Move batch data to the target device.\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "                # Forward pass.\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # Calculate loss.\n",
    "                loss = criterion(outputs.view(-1, outputs.size(-1)), targets.view(-1))\n",
    "\n",
    "                # Check for NaN loss during validation.\n",
    "                if torch.isnan(loss):\n",
    "                     print(f\"Warning: NaN loss detected during validation epoch {epoch}. Skipping batch contribution.\")\n",
    "                     continue\n",
    "\n",
    "                total_val_loss += loss.item()\n",
    "                num_val_batches += 1\n",
    "\n",
    "        # Calculate average validation loss for the epoch.\n",
    "        if num_val_batches == 0:\n",
    "            print(f\"Warning: No batches processed in validation epoch {epoch}. Check validation loader.\")\n",
    "            avg_val_loss = float('inf') # Assign infinity if no validation batches.\n",
    "        else:\n",
    "            avg_val_loss = total_val_loss / num_val_batches\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        epoch_duration = time.time() - epoch_start\n",
    "        # Get the current learning rate from the optimizer.\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        # Print epoch summary.\n",
    "        print(f\"Epoch {epoch:02d}/{num_epochs} | LR: {current_lr:.6f} | Train Loss: {avg_train_loss:.4f} | \"\n",
    "              f\"Val Loss: {avg_val_loss:.4f} | Duration: {epoch_duration:.2f}s\")\n",
    "\n",
    "        # --- Learning Rate Scheduling ---\n",
    "        # Step the scheduler based on the average validation loss.\n",
    "        # ReduceLROnPlateau will decrease LR if `avg_val_loss` hasn't improved for `scheduler.patience` epochs.\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        # --- Early Stopping Logic ---\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            # Validation loss improved.\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_no_improve = 0 # Reset the counter.\n",
    "            # Save the model state dictionary of the best performing model so far.\n",
    "            # Clone tensors to CPU to avoid GPU memory issues when loading later.\n",
    "            best_model_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            print(f\"  New best validation loss: {best_val_loss:.4f}. Saving model state.\")\n",
    "            # Optional: Save the best model checkpoint to disk immediately.\n",
    "            # torch.save(best_model_state, f\"{model_name}_best_checkpoint.pt\")\n",
    "        else:\n",
    "            # Validation loss did not improve.\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"  Validation loss did not improve for {epochs_no_improve} epoch(s).\")\n",
    "            # Check if patience limit is reached.\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping triggered after {epoch} epochs due to no improvement for {patience} epochs.\")\n",
    "                # Load the best model state if it was saved.\n",
    "                if best_model_state:\n",
    "                    print(\"Restoring best model state...\")\n",
    "                    # Ensure the model is on the correct device before loading state dict keys might need mapping if device changed\n",
    "                    model.load_state_dict(best_model_state)\n",
    "                else:\n",
    "                    # This case should ideally not happen if training ran for at least one epoch where loss improved.\n",
    "                    print(\"Warning: Early stopping triggered, but no best model state was saved (potential issue).\")\n",
    "                break # Exit the training loop.\n",
    "\n",
    "    # --- End of Training Loop ---\n",
    "    total_training_time = time.time() - total_start_time\n",
    "    print(f\"--- Finished Training for {model_name} ---\")\n",
    "    print(f\"Total Training Time: {total_training_time:.2f} seconds\")\n",
    "\n",
    "    # If early stopping was triggered, ensure the best model state is loaded before returning.\n",
    "    # This check handles the case where training finishes exactly on the patience limit.\n",
    "    if epochs_no_improve >= patience and best_model_state:\n",
    "        # Check if the current model state is already the best one (it should be if restored in the loop)\n",
    "        # This load is potentially redundant but safe.\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(\"Ensured best model state is loaded after early stopping.\")\n",
    "\n",
    "    return train_losses, val_losses, total_training_time\n",
    "\n",
    "\n",
    "def evaluate_model(model: nn.Module, data_loader: DataLoader, criterion: nn.Module, device: torch.device) -> float:\n",
    "    \"\"\"\n",
    "    Evaluates the model's performance on a given dataset (e.g., validation or test set).\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The trained language model.\n",
    "        data_loader (DataLoader): DataLoader for the evaluation dataset.\n",
    "        criterion (nn.Module): The loss function used during training.\n",
    "        device (torch.device): The device (CPU/GPU) to run evaluation on.\n",
    "\n",
    "    Returns:\n",
    "        float: The average loss over the entire dataset. Returns float('inf') if evaluation fails.\n",
    "    \"\"\"\n",
    "    model.eval() # Set the model to evaluation mode.\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    with torch.no_grad(): # Disable gradient calculations.\n",
    "        for inputs, targets in data_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            # Reshape for loss calculation.\n",
    "            loss = criterion(outputs.view(-1, outputs.size(-1)), targets.view(-1))\n",
    "            # Accumulate loss if it's valid.\n",
    "            if not torch.isnan(loss):\n",
    "                total_loss += loss.item()\n",
    "                num_batches += 1\n",
    "            else:\n",
    "                 print(\"Warning: NaN loss encountered during final evaluation.\")\n",
    "\n",
    "    # Calculate average loss.\n",
    "    if num_batches == 0:\n",
    "        print(\"Error: No batches processed during evaluation. Check data loader.\")\n",
    "        return float('inf') # Indicate error or empty dataset.\n",
    "\n",
    "    return total_loss / num_batches\n",
    "\n",
    "def compute_perplexity(loss: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculates perplexity from the average cross-entropy loss.\n",
    "    Perplexity = exp(average_loss). Lower perplexity indicates a better model fit.\n",
    "\n",
    "    Args:\n",
    "        loss (float): The average cross-entropy loss.\n",
    "\n",
    "    Returns:\n",
    "        float: The calculated perplexity. Returns float('inf') if loss is invalid or too large.\n",
    "    \"\"\"\n",
    "    # Handle invalid loss values.\n",
    "    if loss is None or loss == float('inf') or loss < 0:\n",
    "        return float('inf')\n",
    "    try:\n",
    "        # Calculate perplexity using the exponential function.\n",
    "        perplexity = math.exp(loss)\n",
    "        return perplexity\n",
    "    except OverflowError:\n",
    "        # Handle cases where the loss is extremely large, causing exp() to overflow.\n",
    "        print(f\"Warning: Loss value {loss} too large, resulting in perplexity overflow.\")\n",
    "        return float('inf')\n",
    "\n",
    "def compute_token_accuracy(model: nn.Module, data_loader: DataLoader, device: torch.device) -> float:\n",
    "    \"\"\"\n",
    "    Computes the token-level accuracy of the model on a given dataset.\n",
    "    Accuracy = (Number of correctly predicted tokens) / (Total number of tokens).\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The trained language model.\n",
    "        data_loader (DataLoader): DataLoader for the evaluation dataset.\n",
    "        device (torch.device): The device (CPU/GPU) to run evaluation on.\n",
    "\n",
    "    Returns:\n",
    "        float: The token accuracy (between 0.0 and 1.0).\n",
    "    \"\"\"\n",
    "    model.eval() # Set the model to evaluation mode.\n",
    "    correct = 0 # Counter for correctly predicted tokens.\n",
    "    total = 0   # Counter for total tokens evaluated.\n",
    "    with torch.no_grad(): # Disable gradient calculations.\n",
    "        for inputs, targets in data_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            # Get model logits. Shape: [batch, seq_len, vocab_size]\n",
    "            outputs = model(inputs)\n",
    "            # Get the index of the highest logit for each position (predicted token ID).\n",
    "            # Shape: [batch, seq_len]\n",
    "            predictions = torch.argmax(outputs, dim=-1)\n",
    "            # Compare predictions with the actual target tokens element-wise.\n",
    "            # Sum up the number of correct predictions in the batch.\n",
    "            correct += (predictions == targets).sum().item()\n",
    "            # Add the total number of tokens in the batch targets to the total count.\n",
    "            total += targets.numel()\n",
    "\n",
    "    # Calculate accuracy, handling the case of zero total tokens.\n",
    "    if total == 0:\n",
    "        print(\"Warning: Zero tokens found in accuracy calculation. Check data loader.\")\n",
    "        return 0.0\n",
    "    return correct / total\n",
    "\n",
    "def compute_bleu(reference: str, candidate: str) -> float:\n",
    "    \"\"\"\n",
    "    Computes the BLEU (Bilingual Evaluation Understudy) score between a candidate\n",
    "    (generated) sentence and a reference sentence using NLTK.\n",
    "\n",
    "    Note: BLEU is primarily designed for machine translation and measures n-gram precision.\n",
    "    Its applicability to open-ended text generation can be limited, but it provides\n",
    "    a rough measure of lexical overlap.\n",
    "\n",
    "    Args:\n",
    "        reference (str): The ground truth sentence (target).\n",
    "        candidate (str): The generated sentence (prediction).\n",
    "\n",
    "    Returns:\n",
    "        float: The BLEU score (typically between 0 and 1). Returns 0.0 if candidate\n",
    "               or reference is empty or if an error occurs.\n",
    "    \"\"\"\n",
    "    # Return 0 if either string is empty, as BLEU requires content.\n",
    "    if not candidate or not reference:\n",
    "        return 0.0\n",
    "\n",
    "    # Use a smoothing function (Chen & Cherry method 1) to handle cases where\n",
    "    # higher-order n-grams (e.g., 4-grams) might not appear in the candidate,\n",
    "    # preventing a score of 0 just because of short sentences or lack of overlap.\n",
    "    chencherry = SmoothingFunction()\n",
    "\n",
    "    try:\n",
    "        # Tokenize the reference and candidate sentences using NLTK's word tokenizer.\n",
    "        # `sentence_bleu` expects references as a list of lists of tokens.\n",
    "        ref_tokens = [nltk.word_tokenize(reference.lower())] # Use lowercase for case-insensitive comparison\n",
    "        cand_tokens = nltk.word_tokenize(candidate.lower())\n",
    "\n",
    "        # Calculate BLEU score (defaults to BLEU-4, considering 1 to 4-grams).\n",
    "        bleu = sentence_bleu(ref_tokens, cand_tokens, smoothing_function=chencherry.method1)\n",
    "    except Exception as e:\n",
    "        # Catch potential errors during tokenization or BLEU calculation.\n",
    "        print(f\"Warning: Could not compute BLEU score. Error: {e}\")\n",
    "        # Print truncated versions for debugging.\n",
    "        print(f\"  Reference (truncated): '{reference[:100]}...'\")\n",
    "        print(f\"  Candidate (truncated): '{candidate[:100]}...'\")\n",
    "        bleu = 0.0 # Return 0.0 on error.\n",
    "    return bleu\n",
    "\n",
    "def plot_loss_curve(train_losses: list[float], val_losses: list[float], model_name: str):\n",
    "    \"\"\"\n",
    "    Plots the training and validation loss curves over epochs and saves the plot to a file.\n",
    "    Includes annotations for minimum validation loss and final loss values.\n",
    "\n",
    "    Args:\n",
    "        train_losses (list[float]): List of average training losses per epoch.\n",
    "        val_losses (list[float]): List of average validation losses per epoch.\n",
    "        model_name (str): Name of the model (used for title and filename).\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6)) # Set figure size.\n",
    "    epochs = range(1, len(train_losses) + 1) # X-axis values (epochs).\n",
    "\n",
    "    # Plot training and validation losses.\n",
    "    plt.plot(epochs, train_losses, label=\"Train Loss\", marker='o', linestyle='-', linewidth=2)\n",
    "    plt.plot(epochs, val_losses, label=\"Validation Loss\", marker='s', linestyle='-', linewidth=2)\n",
    "\n",
    "    # Add labels and title.\n",
    "    plt.xlabel(\"Epoch\", fontsize=12)\n",
    "    plt.ylabel(\"Loss\", fontsize=12)\n",
    "    plt.title(f\"{model_name} Training & Validation Loss Curve\", fontsize=14)\n",
    "\n",
    "    # Add legend.\n",
    "    plt.legend(fontsize=12)\n",
    "\n",
    "    # Add grid for better readability.\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "    # --- Annotations ---\n",
    "    # Find minimum validation loss and the epoch it occurred at.\n",
    "    if val_losses: # Ensure val_losses is not empty.\n",
    "        min_val_loss = min(val_losses)\n",
    "        min_val_epoch = val_losses.index(min_val_loss) + 1 # Add 1 for 1-based epoch indexing.\n",
    "        # Add an annotation arrow pointing to the minimum validation loss point.\n",
    "        plt.annotate(f\"Min Val Loss: {min_val_loss:.4f} at Epoch {min_val_epoch}\",\n",
    "                     xy=(min_val_epoch, min_val_loss), # Point coordinates\n",
    "                     xytext=(min_val_epoch + 0.5, min_val_loss + 0.1 * min_val_loss), # Text position (offset)\n",
    "                     arrowprops=dict(facecolor='red', shrink=0.05, width=1, headwidth=8), # Arrow style\n",
    "                     fontsize=10, color='red')\n",
    "\n",
    "    # Annotate final loss values at the last epoch.\n",
    "    if len(epochs) > 0:\n",
    "        final_epoch = epochs[-1]\n",
    "        final_train_loss = train_losses[-1]\n",
    "        final_val_loss = val_losses[-1]\n",
    "        # Use scatter points to highlight the final values.\n",
    "        # `zorder=5` ensures points are plotted on top of lines.\n",
    "        plt.scatter(final_epoch, final_train_loss, color='blue', s=50, zorder=5,\n",
    "                    label=f\"Final Train: {final_train_loss:.4f}\")\n",
    "        plt.scatter(final_epoch, final_val_loss, color='orange', s=50, zorder=5,\n",
    "                    label=f\"Final Val: {final_val_loss:.4f}\")\n",
    "        plt.legend() # Update legend to include scatter point labels.\n",
    "\n",
    "    # Adjust layout to prevent labels from overlapping.\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot to a file.\n",
    "    filename = f\"{model_name}_loss_curve.png\"\n",
    "    plt.savefig(filename, dpi=300) # Save with high resolution.\n",
    "    print(f\"Loss curve saved as {filename}\")\n",
    "\n",
    "    # Display the plot.\n",
    "    plt.show()\n",
    "\n",
    "###############################################################################\n",
    "# Main Training and Evaluation Pipeline\n",
    "###############################################################################\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Orchestrates the entire process:\n",
    "    1. Sets up hyperparameters and file paths.\n",
    "    2. Prepares the tokenizer (trains if necessary).\n",
    "    3. Loads and preprocesses data (tokenization, sequence building).\n",
    "    4. Creates DataLoaders.\n",
    "    5. Initializes RNN, LSTM, and Transformer models.\n",
    "    6. Trains each model with evaluation, LR scheduling, and early stopping.\n",
    "    7. Calculates final metrics (perplexity, accuracy, BLEU).\n",
    "    8. Generates sample text from each model.\n",
    "    9. Saves trained models.\n",
    "    10. Compares model performance using tables and plots.\n",
    "    \"\"\"\n",
    "    global_start = time.time() # Record start time for total duration.\n",
    "\n",
    "        # ------------------ Hyperparameters ------------------\n",
    "    # These values can be tuned based on the specific dataset, task, and available hardware.\n",
    "    vocab_size = 10000         # Target vocabulary size for the BPE tokenizer.\n",
    "    embed_dim = 256            # Dimensionality of token embeddings.\n",
    "    hidden_dim = 128           # Hidden dimension for RNN/LSTM and feed-forward layer in Transformer.\n",
    "                               # Increased from original script for potentially more capacity.\n",
    "    num_layers = 2             # Number of layers in RNN/LSTM/Transformer encoder stacks.\n",
    "    num_heads = 8              # Number of attention heads in Transformer (must divide embed_dim).\n",
    "    max_seq_length = 512       # Maximum length of input sequences fed to the models.\n",
    "    batch_size = 128            # Number of sequences per training batch. Smaller batches can sometimes help generalization\n",
    "                               # and reduce memory usage, but may slow down training.\n",
    "    num_epochs = 30            # Maximum number of training epochs. Early stopping might finish sooner.\n",
    "    learning_rate = 3e-4       # Initial learning rate for the AdamW optimizer.\n",
    "    dropout_rate = 0.2         # Dropout rate for regularization in models.\n",
    "    weight_decay = 0.01        # Weight decay (L2 regularization) for the AdamW optimizer. Helps prevent overfitting.\n",
    "    # Note: pad_token_id is determined dynamically from the tokenizer later.\n",
    "\n",
    "    # ReduceLROnPlateau Scheduler Parameters\n",
    "    lr_patience = 2            # Number of epochs with no improvement in validation loss before reducing LR.\n",
    "    lr_factor = 0.5            # Factor by which the learning rate will be reduced (new_lr = lr * factor).\n",
    "\n",
    "    # Early Stopping Parameters\n",
    "    early_stopping_patience = 5 # Number of epochs with no improvement in validation loss before stopping training.\n",
    "\n",
    "    # ------------------ File Paths ------------------\n",
    "    train_file = \"train.jsonl\"                  # Path to the training data JSONL file.\n",
    "    test_file = \"test.jsonl\"                    # Path to the validation/test data JSONL file.\n",
    "    tokenizer_model_prefix = \"bpe_tokenizer_v1\" # Prefix for saving/loading the tokenizer model.\n",
    "    tokenizer_training_file = \"merged_corpus.txt\" # Path to the text file used FOR training the tokenizer.\n",
    "                                                  # This file will be created if it doesn't exist.\n",
    "\n",
    "    # --- File Existence Checks ---\n",
    "    if not os.path.exists(train_file):\n",
    "        raise FileNotFoundError(f\"Training data file not found: {train_file}\")\n",
    "    if not os.path.exists(test_file):\n",
    "        raise FileNotFoundError(f\"Validation/Test data file not found: {test_file}\")\n",
    "\n",
    "    # ------------------ Prepare Training Text for Tokenizer (if needed) ------------------\n",
    "    # Check if the tokenizer model already exists. If not, prepare the training text file.\n",
    "    if not os.path.exists(f\"{tokenizer_model_prefix}.model\"):\n",
    "        # If the consolidated training text file doesn't exist, create it from the train_file.\n",
    "        if not os.path.exists(tokenizer_training_file):\n",
    "            print(f\"Creating combined text file for tokenizer training: {tokenizer_training_file}\")\n",
    "            texts = []\n",
    "            # Read the training JSONL file.\n",
    "            with open(train_file, \"r\", encoding=\"utf-8\") as f_in:\n",
    "                for line in f_in:\n",
    "                    try:\n",
    "                        # Parse each line as JSON.\n",
    "                        obj = json.loads(line)\n",
    "                        # Extract prompt and completion.\n",
    "                        prompt = obj.get(\"prompt\", \"\")\n",
    "                        completion = obj.get(\"completion\", \"\")\n",
    "                        # Combine and strip whitespace.\n",
    "                        text = (prompt + \" \" + completion).strip()\n",
    "                        # Add non-empty text to the list.\n",
    "                        if text:\n",
    "                            texts.append(text)\n",
    "                    except json.JSONDecodeError:\n",
    "                        # Skip invalid JSON lines.\n",
    "                        continue\n",
    "            # Join all texts with newlines and write to the tokenizer training file.\n",
    "            combined_text = \"\\n\".join(texts)\n",
    "            with open(tokenizer_training_file, \"w\", encoding=\"utf-8\") as f_out:\n",
    "                f_out.write(combined_text)\n",
    "            print(f\"Saved combined text ({len(texts)} entries) to {tokenizer_training_file}\")\n",
    "        else:\n",
    "            # Use the existing file if found.\n",
    "            print(f\"Using existing tokenizer training file: {tokenizer_training_file}\")\n",
    "\n",
    "    # ------------------ Tokenizer Preparation ------------------\n",
    "    # Train the tokenizer if needed, or load the existing one.\n",
    "    sp = train_tokenizer_if_needed(tokenizer_model_prefix=tokenizer_model_prefix,\n",
    "                                    vocab_size=vocab_size,\n",
    "                                    training_text_file=tokenizer_training_file)\n",
    "\n",
    "    # Determine the padding token ID from the loaded tokenizer.\n",
    "    pad_token_id = sp.pad_id()\n",
    "    print(f\"Using Padding Token ID: {pad_token_id}\")\n",
    "\n",
    "    # Set the `ignore_index` for the CrossEntropyLoss function.\n",
    "    # If the tokenizer defined a PAD token (pad_id >= 0), ignore it during loss calculation.\n",
    "    # Otherwise, use the PyTorch default ignore_index (-100), which assumes no padding ID needs ignoring.\n",
    "    ignore_index = pad_token_id if pad_token_id >= 0 else -100\n",
    "\n",
    "    # Get the actual vocabulary size from the trained tokenizer (might differ slightly from target).\n",
    "    effective_vocab_size = sp.vocab_size()\n",
    "    print(f\"Effective vocabulary size: {effective_vocab_size}\")\n",
    "\n",
    "    # ------------------ Load and Tokenize Datasets ------------------\n",
    "    print(\"\\nLoading and tokenizing datasets...\")\n",
    "    # Tokenize the training and validation/test files into flat lists of token IDs.\n",
    "    train_tokens = load_and_tokenize(train_file, sp)\n",
    "    val_tokens = load_and_tokenize(test_file, sp)\n",
    "\n",
    "    # ------------------ Build Fixed-Length Token Sequences ------------------\n",
    "    print(\"\\nBuilding sequences...\")\n",
    "    # Create overlapping sequences of length `max_seq_length + 1`.\n",
    "    train_seqs = build_sequences(train_tokens, max_seq_length)\n",
    "    val_seqs = build_sequences(val_tokens, max_seq_length)\n",
    "    print(f\"Number of training sequences created: {len(train_seqs)}\")\n",
    "    print(f\"Number of validation sequences created: {len(val_seqs)}\")\n",
    "\n",
    "    # Check if sequence creation was successful.\n",
    "    if not train_seqs or not val_seqs:\n",
    "        raise ValueError(\"Failed to create training or validation sequences. \"\n",
    "                         \"Check data loading, tokenization, and sequence length.\")\n",
    "\n",
    "    # ------------------ Create Dataset Objects and DataLoaders ------------------\n",
    "    print(\"\\nCreating Dataset objects and DataLoaders...\")\n",
    "    # Instantiate custom Dataset objects.\n",
    "    train_dataset = LanguageModelDataset(train_seqs, max_seq_length)\n",
    "    val_dataset = LanguageModelDataset(val_seqs, max_seq_length)\n",
    "    print(f\"Train dataset size: {len(train_dataset)} samples\")\n",
    "    print(f\"Validation dataset size: {len(val_dataset)} samples\")\n",
    "\n",
    "    # --- DataLoader Configuration ---\n",
    "    # `num_workers`: Number of subprocesses for data loading. `0` means data is loaded in the main process.\n",
    "    # Using `0` is often safer on Windows and macOS and simplifies debugging.\n",
    "    # Higher values can speed up loading on Linux systems with multiple cores, especially if preprocessing is heavy.\n",
    "    num_workers = 0\n",
    "    # `pin_memory`: If True and using GPU, copies tensors into pinned memory before returning them.\n",
    "    # Can speed up data transfer from CPU to GPU.\n",
    "    pin_memory = True if device.type == \"cuda\" else False\n",
    "\n",
    "    # Create DataLoader for training data.\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True, # Shuffle training data each epoch.\n",
    "                              num_workers=num_workers,\n",
    "                              pin_memory=pin_memory)\n",
    "    # Create DataLoader for validation data.\n",
    "    val_loader = DataLoader(val_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False, # No need to shuffle validation data.\n",
    "                            num_workers=num_workers,\n",
    "                            pin_memory=pin_memory)\n",
    "\n",
    "    # ------------------ Initialize Models ------------------\n",
    "    print(\"\\nInitializing models...\")\n",
    "    # Create instances of the three models. Use the effective vocabulary size.\n",
    "    models = {\n",
    "        #\"RNN\": RNNLanguageModel(effective_vocab_size, embed_dim, hidden_dim, num_layers, dropout=dropout_rate),\n",
    "        #\"LSTM\": LSTMLanguageModel(effective_vocab_size, embed_dim, hidden_dim, num_layers, dropout=dropout_rate),\n",
    "        \"Transformer\": TransformerLanguageModel(effective_vocab_size, embed_dim, num_heads, hidden_dim,\n",
    "                                               num_layers, max_seq_length, dropout=dropout_rate)\n",
    "    }\n",
    "\n",
    "    # Dictionary to store evaluation results for each model.\n",
    "    model_results = {}\n",
    "\n",
    "    # ------------------ Train, Evaluate and Compare Models ------------------\n",
    "    # Loop through each model type (RNN, LSTM, Transformer).\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n===== Processing Model: {name} =====\")\n",
    "        # Move model to the target device.\n",
    "        model.to(device)\n",
    "\n",
    "        # Count and print the number of trainable parameters.\n",
    "        num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        print(f\"Model: {name}, Trainable Parameters: {num_params:,}\")\n",
    "\n",
    "        # --- Setup for Training ---\n",
    "        # Loss Function: CrossEntropyLoss is standard for multi-class classification (predicting the next token).\n",
    "        # `ignore_index` ensures that padding tokens (if used) do not contribute to the loss.\n",
    "        criterion = nn.CrossEntropyLoss(ignore_index=ignore_index)\n",
    "\n",
    "        # Optimizer: AdamW is Adam with decoupled weight decay, often preferred for Transformers.\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "        # Learning Rate Scheduler: Reduces LR when validation loss stops improving.\n",
    "        # `mode='min'`: Reduce LR when the monitored quantity (val loss) stops decreasing.\n",
    "        # `factor`: Multiplicative factor for LR reduction.\n",
    "        # `patience`: Number of epochs to wait before reducing LR.\n",
    "        # `verbose=False`: Removed deprecated argument. Progress is logged manually.\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=lr_factor, patience=lr_patience)\n",
    "\n",
    "        # --- Train the Model ---\n",
    "        # Calls the training function, which handles the epoch loop, early stopping, etc.\n",
    "        train_losses, val_losses, training_time = train_model(\n",
    "            model, train_loader, val_loader, num_epochs,\n",
    "            criterion, optimizer, scheduler, device,\n",
    "            patience=early_stopping_patience, model_name=name\n",
    "        )\n",
    "\n",
    "        # --- Plot Loss Curves ---\n",
    "        # Visualize the training and validation loss progression.\n",
    "        plot_loss_curve(train_losses, val_losses, name)\n",
    "\n",
    "        # --- Final Evaluation ---\n",
    "        # Evaluate the final model (best one loaded by `train_model` if early stopping occurred) on the validation set.\n",
    "        print(f\"\\n--- Evaluating Final {name} Model on Validation Set ---\")\n",
    "        final_val_loss = evaluate_model(model, val_loader, criterion, device)\n",
    "        # Calculate final perplexity and token accuracy based on the final validation loss.\n",
    "        perplexity = compute_perplexity(final_val_loss)\n",
    "        token_accuracy = compute_token_accuracy(model, val_loader, device) * 100 # Convert to percentage.\n",
    "\n",
    "        # --- BLEU Score Calculation ---\n",
    "        # Calculate BLEU score on a sample of the validation set for an indicative measure.\n",
    "        num_bleu_samples = 50 # Number of samples to use for BLEU calculation.\n",
    "        total_bleu = 0.0\n",
    "        bleu_samples_evaluated = 0\n",
    "        if len(val_dataset) > 0:\n",
    "            print(f\"Calculating BLEU score on {min(num_bleu_samples, len(val_dataset))} validation samples...\")\n",
    "            # Ensure we don't try to sample more items than available in the validation set.\n",
    "            indices_to_sample = random.sample(range(len(val_dataset)), k=min(num_bleu_samples, len(val_dataset)))\n",
    "\n",
    "            for idx in indices_to_sample:\n",
    "                # Get input and target tensors for the sample.\n",
    "                sample_input_tokens, sample_target_tokens = val_dataset[idx]\n",
    "                # Decode tokens back to text for prompt and reference.\n",
    "                # Convert tensors to lists before decoding.\n",
    "                prompt_text = sp.decode(sample_input_tokens.tolist())\n",
    "                reference_text = sp.decode(sample_target_tokens.tolist()) # The ground truth completion/next sequence.\n",
    "\n",
    "                # Generate text using the trained model.\n",
    "                # Use a moderate temperature (e.g., 0.7) for generation, as greedy decoding (temp~0)\n",
    "                # might produce repetitive text, potentially lowering BLEU.\n",
    "                generated_text = model.prompt(sp, prompt_text, max_length=max_seq_length, temperature=0.7)\n",
    "\n",
    "                # Note: The generated text includes the prompt. The reference_text corresponds to the target sequence (shifted input).\n",
    "                # For a fairer comparison, one might extract only the generated part after the prompt,\n",
    "                # but this simple approach compares the full generated sequence against the target sequence.\n",
    "                bleu_score_sample = compute_bleu(reference_text, generated_text)\n",
    "                total_bleu += bleu_score_sample\n",
    "                bleu_samples_evaluated += 1\n",
    "\n",
    "            # Calculate the average BLEU score over the samples.\n",
    "            avg_bleu = total_bleu / bleu_samples_evaluated if bleu_samples_evaluated > 0 else 0.0\n",
    "            print(f\"Average BLEU-{num_bleu_samples} score: {avg_bleu:.4f}\")\n",
    "        else:\n",
    "            # Handle case where validation dataset is empty.\n",
    "            avg_bleu = 0.0\n",
    "            print(\"Validation dataset is empty, cannot compute BLEU score.\")\n",
    "        # --- End BLEU Score Calculation ---\n",
    "\n",
    "        # --- Print Evaluation Summary ---\n",
    "        print(f\"\\n--- {name} Final Evaluation Summary ---\")\n",
    "        print(f\"  Validation Loss: {final_val_loss:.4f}\")\n",
    "        print(f\"  Perplexity:        {perplexity:.2f}\")\n",
    "        print(f\"  Token Accuracy:    {token_accuracy:.2f}%\")\n",
    "        print(f\"  Avg BLEU Score:    {avg_bleu:.4f} (Sampled, lower temp generation)\")\n",
    "        print(\"  (Note: Perplexity/Accuracy reflect next-token prediction; BLEU reflects n-gram overlap in generated samples)\")\n",
    "\n",
    "                # --- Generate Sample Outputs ---\n",
    "        # 1) â€œBest way to learn programmingâ€ prompt\n",
    "        fixed_prompt = \"The best way to learn programming is\"\n",
    "        print(\"\\n--- Sample Generations (Prompt 1) ---\")\n",
    "        print(f\"Prompt: '{fixed_prompt}'\")\n",
    "        for temp in [0.5, 1.0, 1.5]:\n",
    "            sample_output = model.prompt(sp, fixed_prompt, max_length=60, temperature=temp)\n",
    "            print(f\"  Temp={temp:.1f}: {sample_output}\")\n",
    "\n",
    "        # 2) â€œWhich do you prefer? Cats or Dogs?â€ prompt\n",
    "        second_prompt = \"Which do you prefer? Cats or Dogs?\"\n",
    "        print(\"\\n--- Sample Generations (Prompt 2) ---\")\n",
    "        print(f\"Prompt: '{second_prompt}'\")\n",
    "        for temp in [0.5, 1.0, 1.5]:\n",
    "            sample_output = model.prompt(sp, second_prompt, max_length=30, temperature=temp)\n",
    "            print(f\"  Temp={temp:.1f}: {sample_output}\")\n",
    "\n",
    "\n",
    "        # --- Save the Trained Model ---\n",
    "        # Save the state dictionary of the final (best) model.\n",
    "        model_save_path = f\"{name}_model_final.pt\"\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"\\n{name} model state dictionary saved to {model_save_path}\")\n",
    "\n",
    "        # --- Store Results ---\n",
    "        # Store the key metrics for this model in the results dictionary.\n",
    "        model_results[name] = {\n",
    "            \"ValLoss\": final_val_loss,\n",
    "            \"Perplexity\": perplexity,\n",
    "            \"Token Accuracy (%)\": token_accuracy,\n",
    "            \"BLEU Score\": avg_bleu,\n",
    "            \"Training Time (s)\": training_time,\n",
    "            \"Parameters\": num_params\n",
    "        }\n",
    "\n",
    "    # ------------------ Compare Model Performance ------------------\n",
    "    print(\"\\n===== Model Performance Comparison =====\")\n",
    "    # Define table header.\n",
    "    header = f\"{'Model':<15} {'Parameters':<15} {'Perplexity':<12} {'Token Acc (%)':<15} {'BLEU Score':<12} {'Train Time (s)':<15}\"\n",
    "    print(header)\n",
    "    print(\"-\" * len(header)) # Print separator line.\n",
    "    # Print metrics for each model.\n",
    "    for model_name, metrics in model_results.items():\n",
    "        print(f\"{model_name:<15} {metrics['Parameters']:, <14} {metrics['Perplexity']:<12.2f} \"\n",
    "              f\"{metrics['Token Accuracy (%)']:<15.2f} {metrics['BLEU Score']:<12.4f} {metrics['Training Time (s)']:<15.2f}\")\n",
    "\n",
    "    # --- Create Comparative Bar Plots ---\n",
    "    # Extract metrics for plotting.\n",
    "    model_names = list(model_results.keys())\n",
    "    perplexities = [model_results[m][\"Perplexity\"] for m in model_names]\n",
    "    accuracies = [model_results[m][\"Token Accuracy (%)\"] for m in model_names]\n",
    "    bleu_scores = [model_results[m][\"BLEU Score\"] for m in model_names]\n",
    "    train_times = [model_results[m][\"Training Time (s)\"] for m in model_names]\n",
    "    # params = [model_results[m][\"Parameters\"] for m in model_names] # Could also plot parameters\n",
    "\n",
    "    # Plotting setup.\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(14, 10)) # Create a 2x2 grid of subplots.\n",
    "    x = np.arange(len(model_names)) # X-axis positions for bars.\n",
    "    width = 0.3 # Width of the bars.\n",
    "\n",
    "    # Plot 1: Perplexity (Lower is better)\n",
    "    bars1 = axs[0, 0].bar(x, perplexities, width, color=\"skyblue\", label='Perplexity')\n",
    "    axs[0, 0].set_ylabel('Perplexity')\n",
    "    axs[0, 0].set_title('Validation Perplexity (Lower is Better)')\n",
    "    axs[0, 0].set_xticks(x)\n",
    "    axs[0, 0].set_xticklabels(model_names)\n",
    "    axs[0, 0].bar_label(bars1, fmt='%.2f') # Add labels on top of bars.\n",
    "\n",
    "    # Plot 2: Token Accuracy (Higher is better)\n",
    "    bars2 = axs[0, 1].bar(x, accuracies, width, color=\"lightgreen\", label='Accuracy')\n",
    "    axs[0, 1].set_ylabel('Accuracy (%)')\n",
    "    axs[0, 1].set_title('Validation Token Accuracy (Higher is Better)')\n",
    "    axs[0, 1].set_xticks(x)\n",
    "    axs[0, 1].set_xticklabels(model_names)\n",
    "    # Adjust y-axis limits for better visualization if values are close.\n",
    "    if accuracies:\n",
    "        axs[0, 1].set_ylim(bottom=max(0, min(accuracies) - 5), top=min(100, max(accuracies) + 5))\n",
    "    axs[0, 1].bar_label(bars2, fmt='%.2f')\n",
    "\n",
    "    # Plot 3: BLEU Score (Higher is better, context dependent)\n",
    "    bars3 = axs[1, 0].bar(x, bleu_scores, width, color=\"salmon\", label='BLEU')\n",
    "    axs[1, 0].set_ylabel('BLEU Score')\n",
    "    axs[1, 0].set_title(f'Average BLEU-{num_bleu_samples} Score (Higher is Better)')\n",
    "    axs[1, 0].set_xticks(x)\n",
    "    axs[1, 0].set_xticklabels(model_names)\n",
    "    axs[1, 0].bar_label(bars3, fmt='%.4f')\n",
    "\n",
    "    # Plot 4: Training Time\n",
    "    bars4 = axs[1, 1].bar(x, train_times, width, color=\"plum\", label='Time')\n",
    "    axs[1, 1].set_ylabel('Time (s)')\n",
    "    axs[1, 1].set_title('Total Training Time')\n",
    "    axs[1, 1].set_xticks(x)\n",
    "    axs[1, 1].set_xticklabels(model_names)\n",
    "    axs[1, 1].bar_label(bars4, fmt='%.1f')\n",
    "\n",
    "    # Add overall title and adjust layout.\n",
    "    plt.suptitle(\"Model Performance Comparison\", fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout to make space for suptitle.\n",
    "\n",
    "    # Save the comparison plot.\n",
    "    comparison_plot_path = \"model_performance_comparison.png\"\n",
    "    plt.savefig(comparison_plot_path, dpi=300)\n",
    "    print(f\"\\nComparison plot saved as {comparison_plot_path}\")\n",
    "    plt.show() # Display the plot.\n",
    "\n",
    "    # --- Final Timing ---\n",
    "    total_time = time.time() - global_start\n",
    "    print(f\"\\nScript finished. Total elapsed time: {total_time / 60:.2f} minutes\")\n",
    "\n",
    "# --- Script Entry Point ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Execute the main function when the script is run directly.\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
