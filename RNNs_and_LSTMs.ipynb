{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add RNNs and LSTMs notebook, remove unused Untitled-1.ipynb, and update .DS_Store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/mubaraqolojo/Downloads/RNN and LSTMs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç JSON Sample Entry:\n",
      "{\n",
      "  \"prompt\": \"are occasions on which the governors and the governed meet together,at festivals, on a journey, voyaging or fighting. the sturdy pauper finds that in the hour of danger he is not despised; he sees the rich man puffing and panting, and\",\n",
      "  \"completion\": \"draws\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "train_file = \"train.jsonl\"\n",
    "\n",
    "with open(train_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if line.strip():\n",
    "            obj = json.loads(line)\n",
    "            print(\"üîç JSON Sample Entry:\")\n",
    "            print(json.dumps(obj, indent=2))\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/mubaraqolojo/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Foundational AI Project 2 ‚Äì Language Modeling with RNNs, LSTMs, and Transformer (Graduate Version)\n",
    "\n",
    "This script trains three language models (RNN, LSTM, Transformer) for text generation.\n",
    "It uses a SentencePiece BPE tokenizer (vocab size=10000) to tokenize text from JSONL files,\n",
    "builds fixed-length sequences via a sliding window approach, and trains the models\n",
    "using early stopping with a cosine annealing learning rate scheduler.\n",
    "Evaluation metrics include perplexity (exp(cross-entropy loss)), token accuracy,\n",
    "and BLEU score (computed with nltk). Sample outputs and loss curves with detailed plots\n",
    "are generated, and model performance is compared.\n",
    "Graduate-level requirements such as temperature-based decoding are supported in the prompt methods.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR  # Cosine learning rate scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sentencepiece as spm  # for subword tokenization\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[‚úì] Using device: mps\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Select computation device: GPU if available, otherwise CPU.\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"[‚úì] Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positional encoding created with shape: torch.Size([1, 512, 256])\n",
      "Sample input shape: torch.Size([2, 10, 256])\n",
      "Sample encoded shape: torch.Size([2, 10, 256])\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Positional Encoding Module\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Computes sinusoidal positional encodings (from \"Attention is All You Need\").\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim, max_len=512, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        pos_enc = torch.zeros(max_len, embed_dim)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, embed_dim, 2, dtype=torch.float) *\n",
    "                             -(math.log(10000.0) / embed_dim))\n",
    "        pos_enc[:, 0::2] = torch.sin(position * div_term)\n",
    "        pos_enc[:, 1::2] = torch.cos(position * div_term)\n",
    "        pos_enc = pos_enc.unsqueeze(0)  # shape: [1, max_len, embed_dim]\n",
    "        self.register_buffer(\"pos_enc\", pos_enc)\n",
    "        print(f\"Positional encoding created with shape: {self.pos_enc.shape}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, seq_length, embed_dim]\n",
    "        seq_len = x.size(1)\n",
    "        x = x + self.pos_enc[:, :seq_len]\n",
    "        return self.dropout(x)\n",
    "\n",
    "# Debug: create a sample positional encoding and print a slice\n",
    "sample_embed = torch.randn(2, 10, 256)  # e.g., batch 2, sequence length 10, embedding dim 256\n",
    "pe = PositionalEncoding(embed_dim=256, max_len=512, dropout=0.0)\n",
    "encoded = pe(sample_embed)\n",
    "print(\"Sample input shape:\", sample_embed.shape)\n",
    "print(\"Sample encoded shape:\", encoded.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample mask (5x5):\n",
      "tensor([[0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Helper functions\n",
    "\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    \"\"\"\n",
    "    Generates a causal mask for transformer models.\n",
    "    Upper-triangular matrix with -inf above the diagonal.\n",
    "    \"\"\"\n",
    "    mask = torch.triu(torch.ones(sz, sz), diagonal=1)\n",
    "    mask = mask.masked_fill(mask == 1, float('-inf'))\n",
    "    return mask\n",
    "\n",
    "# Test the mask generation:\n",
    "mask = generate_square_subsequent_mask(5)\n",
    "print(\"Sample mask (5x5):\")\n",
    "print(mask)\n",
    "\n",
    "def train_tokenizer_if_needed(tokenizer_model_prefix=\"tokenizer\", vocab_size=10000, training_text_file=\"merged_corpus.txt\"):\n",
    "    \"\"\"\n",
    "    Trains SentencePiece model if it does not already exist.\n",
    "    \"\"\"\n",
    "    model_file = f\"{tokenizer_model_prefix}.model\"\n",
    "    if not os.path.exists(model_file):\n",
    "        print(\"Training tokenizer...\")\n",
    "        # Read training text\n",
    "        with open(training_text_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            training_text = f.read()\n",
    "        # Write temporary file for SentencePiece trainer\n",
    "        with open(\"temp_training.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(training_text)\n",
    "        train_command = f\"--input=temp_training.txt --model_prefix={tokenizer_model_prefix} --vocab_size={vocab_size} --model_type=bpe --character_coverage=1.0 --pad_id=3 --pad_piece=[PAD]\"\n",
    "        print(\"Training command:\", train_command)\n",
    "        spm.SentencePieceTrainer.train(train_command)\n",
    "        os.remove(\"temp_training.txt\")\n",
    "    sp = spm.SentencePieceProcessor(model_file=model_file)\n",
    "    return sp\n",
    "\n",
    "def load_and_tokenize(file_path, sp):\n",
    "    \"\"\"\n",
    "    Loads JSONL file and tokenizes each entry (combining \"prompt\" and \"completion\").\n",
    "    \"\"\"\n",
    "    texts = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                obj = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "            prompt = obj.get(\"prompt\", \"\")\n",
    "            completion = obj.get(\"completion\", \"\")\n",
    "            text = (prompt + \" \" + completion).strip()\n",
    "            if text:\n",
    "                texts.append(text)\n",
    "    combined = \"\\n\".join(texts)\n",
    "    print(f\"Loaded {len(texts)} text entries from {file_path}. Total length: {len(combined)} characters\")\n",
    "    return sp.encode(combined, out_type=int)\n",
    "\n",
    "def build_sequences(token_ids, seq_length):\n",
    "    \"\"\"\n",
    "    Build fixed-length overlapping sequences (length = seq_length+1) from token IDs.\n",
    "    \"\"\"\n",
    "    sequences = [token_ids[i:i+seq_length+1] for i in range(len(token_ids) - seq_length)]\n",
    "    print(f\"Created {len(sequences)} sequences of length {seq_length+1}.\")\n",
    "    return sequences\n",
    "\n",
    "# You might add tests for these functions after training the tokenizer or using a sample text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 180 sequences of length 21.\n",
      "Dataset initialized with 180 samples.\n",
      "First sample from dataset: (tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19]), tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "        19, 20]))\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Custom Dataset for language modeling\n",
    "class LanguageModelDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset for language modeling.\n",
    "    Each sample is a tuple (input_tokens, target_tokens) where target is input shifted by one.\n",
    "    \"\"\"\n",
    "    def __init__(self, sequences, seq_length):\n",
    "        # Only use sequences that are exactly seq_length+1 long.\n",
    "        self.samples = [(seq[:-1], seq[1:]) for seq in sequences if len(seq) == seq_length + 1]\n",
    "        print(f\"Dataset initialized with {len(self.samples)} samples.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inp, target = self.samples[idx]\n",
    "        return torch.tensor(inp, dtype=torch.long), torch.tensor(target, dtype=torch.long)\n",
    "\n",
    "# Debug: create a small dummy dataset sample:\n",
    "dummy_tokens = list(range(200))  # dummy token IDs\n",
    "dummy_seqs = build_sequences(dummy_tokens, seq_length=20)\n",
    "dummy_dataset = LanguageModelDataset(dummy_seqs, seq_length=20)\n",
    "print(\"First sample from dataset:\", dummy_dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Model Definitions: RNN, LSTM, and Transformer\n",
    "###############################################################################\n",
    "class RNNLanguageModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Vanilla RNN-based language model.\n",
    "    \n",
    "    Architecture:\n",
    "      - Embedding layer.\n",
    "      - One or more RNN layers.\n",
    "      - Fully-connected layer to produce token logits.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn = nn.RNN(embed_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, seq_length]\n",
    "        embeds = self.embedding(x)  # [batch_size, seq_length, embed_dim]\n",
    "        output, _ = self.rnn(embeds)  # [batch_size, seq_length, hidden_dim]\n",
    "        logits = self.fc(output)      # [batch_size, seq_length, vocab_size]\n",
    "        return logits\n",
    "\n",
    "    def prompt(self, tokenizer, prompt_text, max_length=128, temperature=1.0, pad_token_id=3):\n",
    "        return generate_text(self, tokenizer, prompt_text, max_length, temperature, pad_token_id)\n",
    "\n",
    "class LSTMLanguageModel(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM-based language model.\n",
    "    \n",
    "    Architecture:\n",
    "      - Embedding layer.\n",
    "      - One or more LSTM layers.\n",
    "      - Fully-connected layer to output token probabilities.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, seq_length]\n",
    "        embeds = self.embedding(x)  # [batch_size, seq_length, embed_dim]\n",
    "        output, _ = self.lstm(embeds)  # [batch_size, seq_length, hidden_dim]\n",
    "        logits = self.fc(output)       # [batch_size, seq_length, vocab_size]\n",
    "        return logits\n",
    "\n",
    "    def prompt(self, tokenizer, prompt_text, max_length=128, temperature=1.0, pad_token_id=3):\n",
    "        return generate_text(self, tokenizer, prompt_text, max_length, temperature, pad_token_id)\n",
    "\n",
    "class TransformerLanguageModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer-based language model.\n",
    "    \n",
    "    Architecture:\n",
    "      - Embedding layer followed by positional encoding.\n",
    "      - Transformer encoder to capture long-range dependencies.\n",
    "      - Fully-connected output layer producing vocabulary logits.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, hidden_dim, num_layers, max_seq_length, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.pos_encoder = PositionalEncoding(embed_dim, max_len=max_seq_length, dropout=dropout)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads,\n",
    "                                                   dim_feedforward=hidden_dim, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.fc = nn.Linear(embed_dim, vocab_size)\n",
    "    \n",
    "    def forward(self, x, src_mask=None, src_key_padding_mask=None):\n",
    "        # x: [batch_size, seq_length]\n",
    "        embeds = self.embedding(x)  # [batch_size, seq_length, embed_dim]\n",
    "        encoded = self.pos_encoder(embeds)\n",
    "        # Transformer expects input shape [seq_length, batch_size, embed_dim]\n",
    "        encoded = encoded.transpose(0, 1)\n",
    "        if src_mask is None:\n",
    "            seq_len = x.size(1)\n",
    "            src_mask = generate_square_subsequent_mask(seq_len).to(x.device)\n",
    "        transformer_out = self.transformer_encoder(encoded, mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
    "        # In case the transformer encoder returns a tuple, extract the tensor.\n",
    "        if isinstance(transformer_out, tuple):\n",
    "            transformer_out = transformer_out[0]\n",
    "        transformer_out = transformer_out.transpose(0, 1)  # [batch_size, seq_length, embed_dim]\n",
    "        logits = self.fc(transformer_out)\n",
    "        return logits\n",
    "\n",
    "    def prompt(self, tokenizer, prompt_text, max_length=128, temperature=1.0, pad_token_id=3):\n",
    "        return generate_text(self, tokenizer, prompt_text, max_length, temperature, pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Functions for text generation, training, and evaluation.\n",
    "def generate_text(model, tokenizer, prompt_text, max_length=128, temperature=1.0, pad_token_id=3):\n",
    "    \"\"\"\n",
    "    Generate text using autoregressive sampling.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    token_ids = tokenizer.encode(prompt_text, out_type=int)\n",
    "    generated = token_ids.copy()\n",
    "    model_device = next(model.parameters()).device\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            input_ids = torch.tensor([generated], dtype=torch.long, device=model_device)\n",
    "            logits = model(input_ids)  # expected shape: [1, seq_len, vocab_size]\n",
    "            next_logits = logits[0, -1, :]\n",
    "            if temperature < 1e-5:\n",
    "                next_token = torch.argmax(next_logits).item()\n",
    "            else:\n",
    "                scaled_logits = next_logits / temperature\n",
    "                probs = torch.softmax(scaled_logits, dim=0)\n",
    "                next_token = torch.multinomial(probs, num_samples=1).item()\n",
    "            generated.append(next_token)\n",
    "            # Here, you might check and break if an EOS token is generated.\n",
    "            if next_token == pad_token_id:  # assuming pad token acts as EOS here\n",
    "                break\n",
    "    return tokenizer.decode(generated)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs, criterion, optimizer, scheduler, device, pad_token_id, patience=5):\n",
    "    \"\"\"\n",
    "    Trains the model for the specified number of epochs with early stopping.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    train_losses, val_losses = [], []\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        epoch_start = time.time()\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # If model is a Transformer (assumed to have transformer_encoder), use masks\n",
    "            if hasattr(model, \"transformer_encoder\"):\n",
    "                seq_len = inputs.size(1)\n",
    "                src_mask = generate_square_subsequent_mask(seq_len).to(device)\n",
    "                # Here, using (inputs == pad_token_id) for key padding mask\n",
    "                src_key_padding_mask = (inputs == pad_token_id)\n",
    "                outputs = model(inputs, src_mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
    "            else:\n",
    "                outputs = model(inputs)\n",
    "            loss = criterion(outputs.view(-1, outputs.size(-1)), targets.view(-1))\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                if hasattr(model, \"transformer_encoder\"):\n",
    "                    seq_len = inputs.size(1)\n",
    "                    src_mask = generate_square_subsequent_mask(seq_len).to(device)\n",
    "                    src_key_padding_mask = (inputs == pad_token_id)\n",
    "                    outputs = model(inputs, src_mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
    "                else:\n",
    "                    outputs = model(inputs)\n",
    "                loss = criterion(outputs.view(-1, outputs.size(-1)), targets.view(-1))\n",
    "                total_val_loss += loss.item()\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        scheduler.step()\n",
    "        epoch_duration = time.time() - epoch_start\n",
    "        print(f\"Epoch {epoch} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Duration: {epoch_duration:.2f}s\")\n",
    "        \n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(\"Early stopping triggered. Restoring best model state.\")\n",
    "                model.load_state_dict(best_model_state)\n",
    "                break\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "def evaluate_model(model, data_loader, criterion, device, pad_token_id):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            if hasattr(model, \"transformer_encoder\"):\n",
    "                seq_len = inputs.size(1)\n",
    "                src_mask = generate_square_subsequent_mask(seq_len).to(device)\n",
    "                src_key_padding_mask = (inputs == pad_token_id)\n",
    "                outputs = model(inputs, src_mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
    "            else:\n",
    "                outputs = model(inputs)\n",
    "            loss = criterion(outputs.view(-1, outputs.size(-1)), targets.view(-1))\n",
    "            total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    print(\"Evaluation loss:\", avg_loss)\n",
    "    return avg_loss\n",
    "\n",
    "# (You could add similar debugging prints inside compute_perplexity/accuracy functions.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Plotting loss curves and comparative performance\n",
    "def plot_loss_curve(train_losses, val_losses, model_name):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    plt.plot(epochs, train_losses, label=\"Train Loss\", marker='o')\n",
    "    plt.plot(epochs, val_losses, label=\"Validation Loss\", marker='s')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(f\"{model_name} Loss Curve\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{model_name}_loss.png\", dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"Loss plot for {model_name} saved as {model_name}_loss.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad Token ID: 3\n",
      "Loaded 39557 text entries from train.jsonl. Total length: 14673121 characters\n",
      "Loaded 9890 text entries from test.jsonl. Total length: 3684340 characters\n",
      "Created 3413350 sequences of length 129.\n",
      "Created 858089 sequences of length 129.\n",
      "Dataset initialized with 3413350 samples.\n",
      "Dataset initialized with 858089 samples.\n",
      "\n",
      "--- Training RNN Model ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 94\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# Run the main function if this cell is executed\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 94\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[12], line 67\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mCosineAnnealingLR(optimizer, T_max\u001b[38;5;241m=\u001b[39mnum_epochs, eta_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n\u001b[1;32m     66\u001b[0m start_model \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 67\u001b[0m train_losses, val_losses \u001b[38;5;241m=\u001b[39m train_model(model, train_loader, val_loader, num_epochs,\n\u001b[1;32m     68\u001b[0m                                         criterion, optimizer, scheduler, device, pad_token_id, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     69\u001b[0m training_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_model\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal training time for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraining_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[10], line 52\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, num_epochs, criterion, optimizer, scheduler, device, pad_token_id, patience)\u001b[0m\n\u001b[1;32m     50\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(inputs, src_mask\u001b[38;5;241m=\u001b[39msrc_mask, src_key_padding_mask\u001b[38;5;241m=\u001b[39msrc_key_padding_mask)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     53\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, outputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), targets\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     54\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not tuple"
     ]
    }
   ],
   "source": [
    "# Cell 7: Main function to combine all pieces\n",
    "def main():\n",
    "    global_start = time.time()\n",
    "    \n",
    "    # Hyperparameters and file paths\n",
    "    vocab_size = 10000\n",
    "    embed_dim = 256\n",
    "    hidden_dim = 128\n",
    "    num_layers = 2\n",
    "    num_heads = 8\n",
    "    max_seq_length = 128\n",
    "    batch_size = 256\n",
    "    num_epochs = 30\n",
    "    learning_rate = 5e-4\n",
    "    dropout_rate = 0.3\n",
    "    weight_decay = 1e-4\n",
    "    tokenizer_training_file = \"merged_corpus.txt\"\n",
    "    train_file = \"train.jsonl\"\n",
    "    test_file = \"test.jsonl\"\n",
    "    \n",
    "    # Check files exist\n",
    "    if not os.path.exists(train_file) or not os.path.exists(test_file):\n",
    "        raise FileNotFoundError(\"train.jsonl and/or test.jsonl not found.\")\n",
    "    \n",
    "    # Prepare tokenizer (train if necessary)\n",
    "    sp = train_tokenizer_if_needed(tokenizer_model_prefix=\"tokenizer\", vocab_size=vocab_size, training_text_file=tokenizer_training_file)\n",
    "    pad_token_id = sp.pad_id()  # retrieve pad token id from SentencePiece\n",
    "    print(\"Pad Token ID:\", pad_token_id)\n",
    "    \n",
    "    # Load and tokenize datasets\n",
    "    train_tokens = load_and_tokenize(train_file, sp)\n",
    "    val_tokens = load_and_tokenize(test_file, sp)\n",
    "    \n",
    "    train_seqs = build_sequences(train_tokens, max_seq_length)\n",
    "    val_seqs = build_sequences(val_tokens, max_seq_length)\n",
    "    \n",
    "    # Create dataset and dataloaders\n",
    "    train_dataset = LanguageModelDataset(train_seqs, max_seq_length)\n",
    "    val_dataset = LanguageModelDataset(val_seqs, max_seq_length)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # ----- Initialize your models here -----\n",
    "    # For example, assume you have defined RNNLanguageModel, LSTMLanguageModel, TransformerLanguageModel\n",
    "    # Here we use placeholders; you must replace with your own model definitions.\n",
    "    models = {\n",
    "        \"RNN\": nn.Sequential(nn.Embedding(vocab_size, embed_dim),\n",
    "                             nn.RNN(embed_dim, hidden_dim, num_layers, batch_first=True),\n",
    "                             nn.Linear(hidden_dim, vocab_size)),\n",
    "        \"LSTM\": nn.Sequential(nn.Embedding(vocab_size, embed_dim),\n",
    "                              nn.LSTM(embed_dim, hidden_dim, num_layers, batch_first=True),\n",
    "                              nn.Linear(hidden_dim, vocab_size)),\n",
    "        # The Transformer model might be more involved. This is a simplified placeholder.\n",
    "        \"Transformer\": nn.Sequential(nn.Embedding(vocab_size, embed_dim),\n",
    "                                     nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout_rate), num_layers=num_layers),\n",
    "                                     nn.Linear(embed_dim, vocab_size))\n",
    "    }\n",
    "    \n",
    "    model_results = {}\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n--- Training {name} Model ---\")\n",
    "        model.to(device)\n",
    "        criterion = nn.CrossEntropyLoss(ignore_index=pad_token_id)\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-5)\n",
    "        start_model = time.time()\n",
    "        train_losses, val_losses = train_model(model, train_loader, val_loader, num_epochs,\n",
    "                                                criterion, optimizer, scheduler, device, pad_token_id, patience=3)\n",
    "        training_time = time.time() - start_model\n",
    "        print(f\"Total training time for {name}: {training_time:.2f} seconds\")\n",
    "        plot_loss_curve(train_losses, val_losses, name)\n",
    "        val_loss = evaluate_model(model, val_loader, criterion, device, pad_token_id)\n",
    "        perplexity = math.exp(val_loss)\n",
    "        print(f\"{name} Model Perplexity: {perplexity:.2f}\")\n",
    "        \n",
    "        # (Optionally, include token accuracy and BLEU score calculation)\n",
    "        # Save model\n",
    "        torch.save(model.state_dict(), f\"{name}_model.pt\")\n",
    "        print(f\"{name} model saved as {name}_model.pt\")\n",
    "        \n",
    "        model_results[name] = {\n",
    "            \"ValLoss\": val_loss,\n",
    "            \"Perplexity\": perplexity,\n",
    "            \"TrainingTime\": training_time\n",
    "        }\n",
    "    total_time = time.time() - global_start\n",
    "    print(\"\\n--- Model Performance Summary ---\")\n",
    "    for model_name, metrics in model_results.items():\n",
    "        print(f\"{model_name}: Perplexity = {metrics['Perplexity']:.2f}, Train Time = {metrics['TrainingTime']:.2f}s\")\n",
    "    print(f\"\\nTotal elapsed time: {total_time:.2f} seconds\")\n",
    "\n",
    "# Run the main function if this cell is executed\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "###############################################################################\n",
    "# Positional Encoding Module\n",
    "###############################################################################\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Computes sinusoidal positional encodings and adds them to token embeddings.\n",
    "    This implementation follows 'Attention is All You Need' (Vaswani et al., 2017).\n",
    "    \n",
    "    Args:\n",
    "        embed_dim (int): Embedding dimension (d_model).\n",
    "        max_len (int): Maximum sequence length (number of positions).\n",
    "        dropout (float): Dropout probability applied after adding positional encodings.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim, max_len=512, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Initialize an empty tensor for positional encoding: shape [max_len, embed_dim]\n",
    "        pos_enc = torch.zeros(max_len, embed_dim)\n",
    "        # Create a column vector of positions [0, 1, ..., max_len-1]\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        # Compute the divisor term for the sinusoidal functions\n",
    "        div_term = torch.exp(torch.arange(0, embed_dim, 2, dtype=torch.float) * -(math.log(10000.0) / embed_dim))\n",
    "        # Apply sine to even indices and cosine to odd indices of the embedding dimension\n",
    "        pos_enc[:, 0::2] = torch.sin(position * div_term)  # even indices: sin(position/scale)\n",
    "        pos_enc[:, 1::2] = torch.cos(position * div_term)  # odd indices: cos(position/scale)\n",
    "        # Add an extra batch dimension so that pos_enc becomes [1, max_len, embed_dim]\n",
    "        pos_enc = pos_enc.unsqueeze(0)\n",
    "        # Register pos_enc as a buffer so it is saved with the model and moved across devices\n",
    "        self.register_buffer(\"pos_enc\", pos_enc)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Adds positional encoding to input tensor x.\n",
    "        \n",
    "        Args:\n",
    "            x (Tensor): Input embeddings of shape [batch_size, seq_length, embed_dim].\n",
    "        Returns:\n",
    "            Tensor: Output embeddings with added positional encoding.\n",
    "        \"\"\"\n",
    "        # Slice the positional encoding to the input sequence length and add to x.\n",
    "        x = x + self.pos_enc[:, :x.size(1)]\n",
    "        # Apply dropout and return\n",
    "        return self.dropout(x)\n",
    "\n",
    "    ###############################################################################\n",
    "# Helper Functions\n",
    "###############################################################################\n",
    "    def generate_square_subsequent_mask(sz):\n",
    "        \"\"\"\n",
    "        Generates a causal mask for Transformer models.\n",
    "        The returned mask is of shape (sz, sz) where positions in the upper triangular (future tokens)\n",
    "        are set to -inf.\n",
    "        \"\"\"\n",
    "        mask = torch.triu(torch.ones(sz, sz), diagonal=1)\n",
    "        mask = mask.masked_fill(mask == 1, float('-inf'))\n",
    "        return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 80\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [token_ids[i:i\u001b[38;5;241m+\u001b[39mseq_length\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(token_ids) \u001b[38;5;241m-\u001b[39m seq_length)]\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m###############################################################################\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Custom Dataset Class for Language Modeling\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m###############################################################################\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLanguageModelDataset\u001b[39;00m(Dataset):\n\u001b[1;32m     81\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m    Custom dataset for language modeling.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    Each sample is a tuple: (input_tokens, target_tokens) where target_tokens is the input shifted by one.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, sequences, seq_length):\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;66;03m# Filter sequences to ensure they have the exact required length.\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "###############################################################################\n",
    "# Data Preparation Functions\n",
    "###############################################################################\n",
    "def train_tokenizer_if_needed(tokenizer_model_prefix=\"tokenizer\", vocab_size=10000, training_text_file=\"merged_corpus.txt\"):\n",
    "    \"\"\"\n",
    "    Trains a SentencePiece tokenizer if the model file is not found.\n",
    "    The tokenizer is used to encode text into subword tokens.\n",
    "    \n",
    "    Args:\n",
    "        tokenizer_model_prefix (str): Prefix for the tokenizer model filename.\n",
    "        vocab_size (int): Subword vocabulary size.\n",
    "        training_text_file (str): Plain text file used to train the tokenizer.\n",
    "    \n",
    "    Returns:\n",
    "        SentencePieceProcessor: The trained tokenizer.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(f\"{tokenizer_model_prefix}.model\"):\n",
    "        print(\"Training tokenizer...\")\n",
    "        with open(training_text_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            training_text = f.read()\n",
    "        with open(\"temp_training.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(training_text)\n",
    "        # Create a fresh SentencePiece model with PAD reserved.\n",
    "        train_command = f\"--input=temp_training.txt --model_prefix={tokenizer_model_prefix} --vocab_size={vocab_size} --model_type=bpe --character_coverage=1.0 --pad_id=3 --pad_piece=[PAD]\"\n",
    "        print(\"Training command:\", train_command)\n",
    "        spm.SentencePieceTrainer.train(train_command)\n",
    "        os.remove(\"temp_training.txt\")\n",
    "    sp = spm.SentencePieceProcessor(model_file=f\"{tokenizer_model_prefix}.model\")\n",
    "    return sp\n",
    "\n",
    "def load_and_tokenize(file_path, sp):\n",
    "    \"\"\"\n",
    "    Loads text data from a JSONL file and tokenizes it.\n",
    "    Each JSON object should have \"prompt\" and \"completion\" fields.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the JSONL file.\n",
    "        sp (SentencePieceProcessor): Trained SentencePiece tokenizer.\n",
    "    \n",
    "    Returns:\n",
    "        list[int]: List of token IDs from the combined text.\n",
    "    \"\"\"\n",
    "    texts = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                # Parse JSON line\n",
    "                obj = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                continue  # Skip lines that are not valid JSON\n",
    "            prompt = obj.get(\"prompt\", \"\")\n",
    "            completion = obj.get(\"completion\", \"\")\n",
    "            # Combine prompt and completion\n",
    "            text = (prompt + \" \" + completion).strip()\n",
    "            if text:\n",
    "                texts.append(text)\n",
    "    # Combine all texts into one large text separated by newlines\n",
    "    combined = \"\\n\".join(texts)\n",
    "    print(f\"Loaded {len(texts)} text entries from {file_path}. Total length: {len(combined)} characters\")\n",
    "    # Tokenize the combined text using SentencePiece\n",
    "    return sp.encode(combined, out_type=int)\n",
    "\n",
    "def build_sequences(token_ids, seq_length):\n",
    "    \"\"\"\n",
    "    Creates overlapping sequences from token IDs.\n",
    "    Each sequence will have (seq_length + 1) tokens to allow input/target pairing.\n",
    "    \n",
    "    Args:\n",
    "        token_ids (list[int]): List of token IDs.\n",
    "        seq_length (int): Desired input sequence length.\n",
    "    \n",
    "    Returns:\n",
    "        list[list[int]]: List where each sublist is a token sequence of length seq_length+1.\n",
    "    \"\"\"\n",
    "    return [token_ids[i:i+seq_length+1] for i in range(len(token_ids) - seq_length)]\n",
    "\n",
    "###############################################################################\n",
    "# Custom Dataset Class for Language Modeling\n",
    "###############################################################################\n",
    "class LanguageModelDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset for language modeling.\n",
    "    Each sample is a tuple: (input_tokens, target_tokens) where target_tokens is the input shifted by one.\n",
    "    \"\"\"\n",
    "    def __init__(self, sequences, seq_length):\n",
    "        # Filter sequences to ensure they have the exact required length.\n",
    "        self.samples = [(seq[:-1], seq[1:]) for seq in sequences if len(seq) == seq_length + 1]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        inp, target = self.samples[idx]\n",
    "        return torch.tensor(inp, dtype=torch.long), torch.tensor(target, dtype=torch.long)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Text Generation and Model Definitions\n",
    "###############################################################################\n",
    "def generate_text(model, tokenizer, prompt_text, max_length=128, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Generates text by autoregressively sampling from the model.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The trained language model.\n",
    "        tokenizer (SentencePieceProcessor): Tokenizer to encode/decode text.\n",
    "        prompt_text (str): The initial text prompt.\n",
    "        max_length (int): Maximum number of tokens to generate (excluding the prompt tokens).\n",
    "        temperature (float): Sampling temperature, where values near 0 imply greedy decoding.\n",
    "    \n",
    "    Returns:\n",
    "        str: The generated text (decoded).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    # Encode prompt text to token IDs.\n",
    "    token_ids = tokenizer.encode(prompt_text, out_type=int)\n",
    "    generated = token_ids.copy()  # Copy prompt tokens to start generation\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            # Prepare input tensor of shape [1, current_length]\n",
    "            input_ids = torch.tensor([generated], dtype=torch.long, device=device)\n",
    "            logits = model(input_ids)  # Forward pass through the model; shape: [1, seq_len, vocab_size]\n",
    "            next_logits = logits[0, -1, :]  # Take the logits for the last time step\n",
    "            # Determine next token\n",
    "            if temperature < 1e-5:\n",
    "                # Greedy: take the token with maximum probability\n",
    "                next_token = torch.argmax(next_logits).item()\n",
    "            else:\n",
    "                # Scale logits by temperature\n",
    "                scaled_logits = next_logits / temperature\n",
    "                # Compute probabilities\n",
    "                probs = torch.softmax(scaled_logits, dim=0)\n",
    "                # Sample the next token\n",
    "                next_token = torch.multinomial(probs, num_samples=1).item()\n",
    "            generated.append(next_token)\n",
    "            # Stop if end-of-sequence token is produced.\n",
    "            if next_token == tokenizer.eos_id():\n",
    "                break\n",
    "    # Decode the generated token IDs back into text.\n",
    "    return tokenizer.decode(generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RNNLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        # Pass dropout_rate to the RNN call (note: dropout in RNN works only if num_layers > 1)\n",
    "        self.rnn = nn.RNN(embed_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout_rate)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "    def forward(self, x):\n",
    "        embeds = self.embedding(x)\n",
    "        output, _ = self.rnn(embeds)\n",
    "        logits = self.fc(output)\n",
    "        return logits\n",
    "    def prompt(self, tokenizer, prompt_text, max_length=128, temperature=1.0, pad_token_id=3):\n",
    "        return generate_text(self, tokenizer, prompt_text, max_length, temperature)\n",
    "\n",
    "class LSTMLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        # Pass dropout_rate to the LSTM call (dropout works only if num_layers > 1)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout_rate)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "    def forward(self, x):\n",
    "        embeds = self.embedding(x)\n",
    "        output, _ = self.lstm(embeds)\n",
    "        logits = self.fc(output)\n",
    "        return logits\n",
    "    def prompt(self, tokenizer, prompt_text, max_length=128, temperature=1.0, pad_token_id=3):\n",
    "        return generate_text(self, tokenizer, prompt_text, max_length, temperature)\n",
    "\n",
    "\n",
    "class TransformerLanguageModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer-based language model.\n",
    "    \n",
    "    Architecture:\n",
    "      - Embedding layer followed by positional encoding.\n",
    "      - Transformer encoder: captures long-range dependencies.\n",
    "      - Fully-connected layer to output vocabulary logits.\n",
    "      \n",
    "    Positional encoding ensures that token order is captured.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, hidden_dim, num_layers, max_seq_length, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        # Incorporate positional encoding to add sequence order information.\n",
    "        self.pos_encoder = PositionalEncoding(embed_dim, max_len=max_seq_length, dropout=dropout)\n",
    "        # Define a single Transformer encoder layer and stack multiple layers.\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads,\n",
    "                                                   dim_feedforward=hidden_dim, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.fc = nn.Linear(embed_dim, vocab_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Convert token indices to embeddings.\n",
    "        embeds = self.embedding(x)  # [batch, seq_length, embed_dim]\n",
    "        # Add positional encodings.\n",
    "        encoded = self.pos_encoder(embeds)\n",
    "        # Transformer expects input shape [seq_length, batch, embed_dim]; so we transpose.\n",
    "        encoded = encoded.transpose(0, 1)\n",
    "        if src_mask is None:\n",
    "            seq_len = x.size(1)\n",
    "            src_mask = generate_square_subsequent_mask(seq_len).to(x.device)\n",
    "        transformer_out = self.transformer_encoder(encoded, mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
    "        transformer_out = transformer_out.transpose(0, 1)  # back to [batch_size, seq_len, embed_dim]\n",
    "        logits = self.fc(transformer_out)\n",
    "        return logits\n",
    "    \n",
    "    def prompt(self, tokenizer, prompt_text, max_length=128, temperature=1.0, pad_token_id=3):\n",
    "        return generate_text(self, tokenizer, prompt_text, max_length, temperature, pad_token_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Training, Evaluation, and Plotting Functions\n",
    "###############################################################################\n",
    "def train_model(model, train_loader, val_loader, num_epochs, criterion, optimizer, scheduler, device, patience=5):\n",
    "    \"\"\"\n",
    "    Trains the model for a maximum number of epochs with early stopping.\n",
    "    \n",
    "    Uses mini-batch gradient descent with gradient clipping and a cosine annealing scheduler.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The language model.\n",
    "        train_loader (DataLoader): Training data loader.\n",
    "        val_loader (DataLoader): Validation data loader.\n",
    "        num_epochs (int): Maximum epochs.\n",
    "        criterion: Loss function (CrossEntropyLoss).\n",
    "        optimizer: Optimizer (e.g., AdamW).\n",
    "        scheduler: CosineAnnealingLR scheduler.\n",
    "        device: Computation device.\n",
    "        patience (int): Number of epochs to wait without improvement for early stopping.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Lists of training and validation losses per epoch.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    train_losses, val_losses = [], []\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()  # Set model to training mode\n",
    "        total_train_loss = 0\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        # Training loop over mini-batches\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # If model is Transformer, use masks in forward pass\n",
    "            if hasattr(model, \"transformer_encoder\"):\n",
    "                seq_len = inputs.size(1)\n",
    "                src_mask = generate_square_subsequent_mask(seq_len).to(device)\n",
    "                src_key_padding_mask = (inputs == pad_token_id)\n",
    "                outputs = model(inputs, src_mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
    "            else:\n",
    "                outputs = model(inputs)\n",
    "            loss = criterion(outputs.view(-1, outputs.size(-1)), targets.view(-1))\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # Validation evaluation\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                if hasattr(model, \"transformer_encoder\"):\n",
    "                    seq_len = inputs.size(1)\n",
    "                    src_mask = generate_square_subsequent_mask(seq_len).to(device)\n",
    "                    src_key_padding_mask = (inputs == pad_token_id)\n",
    "                    outputs = model(inputs, src_mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
    "                else:\n",
    "                    outputs = model(inputs)\n",
    "                loss = criterion(outputs.view(-1, outputs.size(-1)), targets.view(-1))\n",
    "                total_val_loss += loss.item()\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        # Step the LR scheduler after each epoch\n",
    "        scheduler.step()\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        epoch_duration = time.time() - epoch_start\n",
    "        print(f\"Epoch {epoch} | LR: {current_lr:.6f} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Duration: {epoch_duration:.2f}s\")\n",
    "\n",
    "        # Early stopping mechanism: if validation loss doesn't improve, increment counter\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_no_improve = 0\n",
    "            best_model_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(\"Early stopping triggered. Restoring best model state.\")\n",
    "                model.load_state_dict(best_model_state)\n",
    "                break\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "def evaluate_model(model, data_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the provided dataset.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): Trained language model.\n",
    "        data_loader (DataLoader): DataLoader for evaluation.\n",
    "        criterion: Loss function.\n",
    "        device: Computation device.\n",
    "        \n",
    "    Returns:\n",
    "        float: Average loss computed over all batches.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            if hasattr(model, \"transformer_encoder\"):\n",
    "                seq_len = inputs.size(1)\n",
    "                src_mask = generate_square_subsequent_mask(seq_len).to(device)\n",
    "                src_key_padding_mask = (inputs == pad_token_id)\n",
    "                outputs = model(inputs, src_mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
    "            else:\n",
    "                outputs = model(inputs)\n",
    "            loss = criterion(outputs.view(-1, outputs.size(-1)), targets.view(-1))\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "def compute_perplexity(loss):\n",
    "    \"\"\"\n",
    "    Computes perplexity from cross-entropy loss.\n",
    "    \n",
    "    Args:\n",
    "        loss (float): Average cross-entropy loss.\n",
    "    \n",
    "    Returns:\n",
    "        float: Perplexity as exp(loss).\n",
    "    \"\"\"\n",
    "    return math.exp(loss)\n",
    "\n",
    "def compute_token_accuracy(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Computes token-level accuracy over the entire dataset.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): Trained language model.\n",
    "        data_loader (DataLoader): DataLoader for the dataset.\n",
    "        device: Computation device.\n",
    "    \n",
    "    Returns:\n",
    "        float: Fraction of tokens correctly predicted.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            if hasattr(model, \"transformer_encoder\"):\n",
    "                seq_len = inputs.size(1)\n",
    "                src_mask = generate_square_subsequent_mask(seq_len).to(device)\n",
    "                src_key_padding_mask = (inputs == pad_token_id)\n",
    "                outputs = model(inputs, src_mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
    "            else:\n",
    "                outputs = model(inputs)\n",
    "            predictions = torch.argmax(outputs, dim=-1)\n",
    "            correct += (predictions == targets).sum().item()\n",
    "            total += targets.numel()\n",
    "    return correct / total\n",
    "\n",
    "def compute_bleu(reference, candidate):\n",
    "    \"\"\"\n",
    "    Computes BLEU score comparing a reference sentence to a generated candidate sentence.\n",
    "    \n",
    "    Args:\n",
    "        reference (str): Ground truth sentence.\n",
    "        candidate (str): Generated sentence.\n",
    "    \n",
    "    Returns:\n",
    "        float: BLEU score (0 to 1).\n",
    "    \"\"\"\n",
    "    return sentence_bleu([nltk.word_tokenize(reference)], nltk.word_tokenize(candidate))\n",
    "\n",
    "def plot_loss_curve(train_losses, val_losses, model_name):\n",
    "    \"\"\"\n",
    "    Plots the training and validation loss curves with annotations.\n",
    "    \n",
    "    Args:\n",
    "        train_losses (list[float]): Training losses per epoch.\n",
    "        val_losses (list[float]): Validation losses per epoch.\n",
    "        model_name (str): Name of the model (used for title and saving the plot).\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    # Plot training loss with marker circle\n",
    "    plt.plot(epochs, train_losses, label=\"Train Loss\", marker='o', linestyle='-', linewidth=2)\n",
    "    # Plot validation loss with square marker\n",
    "    plt.plot(epochs, val_losses, label=\"Validation Loss\", marker='s', linestyle='-', linewidth=2)\n",
    "    plt.xlabel(\"Epoch\", fontsize=12)\n",
    "    plt.ylabel(\"Loss\", fontsize=12)\n",
    "    plt.title(f\"{model_name} Loss Curve\", fontsize=14)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    # Annotate final loss values with arrows\n",
    "    plt.annotate(f\"Final Train: {train_losses[-1]:.4f}\", xy=(epochs[-1], train_losses[-1]),\n",
    "                 xytext=(epochs[-1]-5, train_losses[-1]+0.05),\n",
    "                 arrowprops=dict(facecolor='blue', shrink=0.05),\n",
    "                 fontsize=10, color='blue')\n",
    "    plt.annotate(f\"Final Val: {val_losses[-1]:.4f}\", xy=(epochs[-1], val_losses[-1]),\n",
    "                 xytext=(epochs[-1]-5, val_losses[-1]+0.05),\n",
    "                 arrowprops=dict(facecolor='red', shrink=0.05),\n",
    "                 fontsize=10, color='red')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{model_name}_loss.png\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokenizer...\n",
      "Training command: --input=temp_training.txt --model_prefix=tokenizer --vocab_size=10000 --model_type=bpe --character_coverage=1.0 --pad_id=3 --pad_piece=[PAD]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(178) LOG(INFO) Running command: --input=temp_training.txt --model_prefix=tokenizer --vocab_size=10000 --model_type=bpe --character_coverage=1.0 --pad_id=3 --pad_piece=[PAD]\n",
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: temp_training.txt\n",
      "  input_format: \n",
      "  model_prefix: tokenizer\n",
      "  model_type: BPE\n",
      "  vocab_size: 10000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: 3\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: [PAD]\n",
      "  unk_surface:  ‚Åá \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: temp_training.txt\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 39557 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: [PAD]\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=15902374\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=48\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 39557 sentences.\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 39557\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 139598\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=411258 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=105970 size=20 all=1669 active=1621 piece=is\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=65720 size=40 all=2610 active=2562 piece=as\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=39559 size=60 all=3364 active=3316 piece=completion\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=30462 size=80 all=4451 active=4403 piece=‚ñÅhis\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22833 size=100 all=5455 active=5407 piece=ur\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=22256 min_freq=1144\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15655 size=120 all=6525 active=1960 piece=ich\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12980 size=140 all=7686 active=3121 piece=‚ñÅle\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11297 size=160 all=8954 active=4389 piece=‚ñÅcon\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9602 size=180 all=10084 active=5519 piece=‚ñÅne\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8113 size=200 all=11163 active=6598 piece=ol\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8033 min_freq=1091\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7126 size=220 all=12795 active=2504 piece=led\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6231 size=240 all=14026 active=3735 piece=os\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5658 size=260 all=15173 active=4882 piece=‚ñÅpl\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5055 size=280 all=16338 active=6047 piece=‚ñÅim\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4653 size=300 all=17436 active=7145 piece=ars\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4633 min_freq=911\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4301 size=320 all=18251 active=1712 piece=‚ñÅcr\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4124 size=340 all=19236 active=2697 piece=ree\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3739 size=360 all=20272 active=3733 piece=‚ñÅabout\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3523 size=380 all=21318 active=4779 piece=‚ñÅgood\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3324 size=400 all=21905 active=5366 piece=‚ñÅbefore\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3319 min_freq=748\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3082 size=420 all=22516 active=1696 piece=ft\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2918 size=440 all=23206 active=2386 piece=cl\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2697 size=460 all=24316 active=3496 piece=int\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2577 size=480 all=25094 active=4274 piece=‚ñÅeyes\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2411 size=500 all=25943 active=5123 piece=omet\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2406 min_freq=580\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2255 size=520 all=26787 active=2114 piece=ied\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2096 size=540 all=27552 active=2879 piece=ause\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2004 size=560 all=28214 active=3541 piece=‚ñÅwhile\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1900 size=580 all=28652 active=3979 piece=‚ñÅtake\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1816 size=600 all=29128 active=4455 piece=lt\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1810 min_freq=476\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1745 size=620 all=29637 active=1929 piece=amp\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1683 size=640 all=30262 active=2554 piece=‚ñÅacc\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1605 size=660 all=30761 active=3053 piece=‚ñÅlooked\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1531 size=680 all=31294 active=3586 piece=‚ñÅlove\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1496 size=700 all=31772 active=4064 piece=‚ñÅcertain\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1494 min_freq=409\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1456 size=720 all=32350 active=2161 piece=‚ñÅseen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1408 size=740 all=32949 active=2760 piece=‚ñÅsoon\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1353 size=760 all=33406 active=3217 piece=‚ñÅtre\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1317 size=780 all=33836 active=3647 piece=ern\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1265 size=800 all=34602 active=4413 piece=‚ñÅdeath\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1263 min_freq=348\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1230 size=820 all=35231 active=2328 piece=‚ñÅson\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1192 size=840 all=35724 active=2821 piece=ited\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1152 size=860 all=36404 active=3501 piece=‚ñÅhour\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1118 size=880 all=36934 active=4031 piece=itu\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1098 size=900 all=37410 active=4507 piece=‚ñÅfull\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1097 min_freq=303\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1076 size=920 all=37854 active=2302 piece=‚ñÅinf\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1049 size=940 all=38160 active=2608 piece=‚ñÅsort\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1020 size=960 all=38623 active=3071 piece=ering\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=998 size=980 all=39039 active=3487 piece=‚ñÅinde\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=976 size=1000 all=39312 active=3760 piece=‚ñÅeverything\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=975 min_freq=274\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=947 size=1020 all=39806 active=2453 piece=‚ñÅprop\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=919 size=1040 all=40293 active=2940 piece=oc\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=894 size=1060 all=40816 active=3463 piece=ully\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=876 size=1080 all=41284 active=3931 piece=‚ñÅinv\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=860 size=1100 all=41611 active=4258 piece=‚ñÅsecond\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=859 min_freq=248\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=837 size=1120 all=41899 active=2357 piece=‚ñÅfre\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=817 size=1140 all=42323 active=2781 piece=‚ñÅsmall\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=804 size=1160 all=42652 active=3110 piece=‚ñÅreason\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=787 size=1180 all=42863 active=3321 piece=‚ñÅhuman\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=764 size=1200 all=43113 active=3571 piece=‚ñÅtom\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=762 min_freq=227\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=748 size=1220 all=43604 active=2636 piece=‚ñÅparis\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=728 size=1240 all=43847 active=2879 piece=‚ñÅdiv\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=711 size=1260 all=44142 active=3174 piece=‚ñÅask\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=701 size=1280 all=44481 active=3513 piece=‚ñÅhus\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=688 size=1300 all=44689 active=3721 piece=‚ñÅexpl\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=688 min_freq=210\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=670 size=1320 all=45004 active=2541 piece=‚ñÅuntil\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=659 size=1340 all=45194 active=2731 piece=‚ñÅshort\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=647 size=1360 all=45479 active=3016 piece=olu\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=638 size=1380 all=45834 active=3371 piece=‚ñÅfal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=625 size=1400 all=46174 active=3711 piece=‚ñÅwithin\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=624 min_freq=197\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=610 size=1420 all=46469 active=2601 piece=iful\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=597 size=1440 all=46706 active=2838 piece=‚ñÅlear\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=585 size=1460 all=47047 active=3179 piece=‚ñÅexist\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=577 size=1480 all=47348 active=3480 piece=‚ñÅrepe\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=567 size=1500 all=47643 active=3775 piece=‚ñÅinstant\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=566 min_freq=185\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=557 size=1520 all=47826 active=2562 piece=‚ñÅcat\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=549 size=1540 all=48187 active=2923 piece=‚ñÅtown\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=538 size=1560 all=48503 active=3239 piece=enty\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=527 size=1580 all=48921 active=3657 piece=‚ñÅhes\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=518 size=1600 all=49142 active=3878 piece=‚ñÅmou\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=518 min_freq=172\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=507 size=1620 all=49402 active=2711 piece=‚ñÅfif\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=499 size=1640 all=49673 active=2982 piece=‚ñÅpleasure\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=488 size=1660 all=49939 active=3248 piece=nard\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=482 size=1680 all=50180 active=3489 piece=sp\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=476 size=1700 all=50598 active=3907 piece=ieur\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=476 min_freq=161\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=471 size=1720 all=50830 active=2757 piece=‚ñÅmod\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=466 size=1740 all=50967 active=2894 piece=lling\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=458 size=1760 all=51167 active=3094 piece=oof\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=452 size=1780 all=51428 active=3355 piece=‚ñÅyouth\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=447 size=1800 all=51610 active=3537 piece=‚ñÅaccord\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=446 min_freq=152\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=439 size=1820 all=51836 active=2804 piece=‚ñÅtears\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=434 size=1840 all=51990 active=2958 piece=‚ñÅja\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=428 size=1860 all=52321 active=3289 piece=ya\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=422 size=1880 all=52565 active=3533 piece=‚ñÅcoun\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=413 size=1900 all=52875 active=3843 piece=‚ñÅsal\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=413 min_freq=143\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=407 size=1920 all=53115 active=2853 piece=‚ñÅnone\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=401 size=1940 all=53337 active=3075 piece=‚ñÅahab\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=394 size=1960 all=53484 active=3222 piece=app\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=390 size=1980 all=53694 active=3432 piece=oyed\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=386 size=2000 all=53902 active=3640 piece=‚ñÅtomorrow\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=386 min_freq=137\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=379 size=2020 all=54223 active=3010 piece=‚ñÅast\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=374 size=2040 all=54408 active=3195 piece=‚ñÅprev\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=369 size=2060 all=54665 active=3452 piece=‚ñÅdu\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=366 size=2080 all=54902 active=3689 piece=‚ñÅtalking\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=360 size=2100 all=55107 active=3894 piece=co\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=360 min_freq=130\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=357 size=2120 all=55494 active=3069 piece=inary\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=352 size=2140 all=55793 active=3368 piece=‚ñÅtroy\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=348 size=2160 all=56052 active=3627 piece=‚ñÅstone\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=344 size=2180 all=56255 active=3830 piece=‚ñÅthrew\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=340 size=2200 all=56521 active=4096 piece=come\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=340 min_freq=122\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=335 size=2220 all=56789 active=3075 piece=‚ñÅlift\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=332 size=2240 all=57005 active=3291 piece=‚ñÅutter\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=327 size=2260 all=57157 active=3443 piece=here\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=323 size=2280 all=57364 active=3650 piece=ism\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=319 size=2300 all=57625 active=3911 piece=‚ñÅunh\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=319 min_freq=116\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=315 size=2320 all=57889 active=3131 piece=‚ñÅdrag\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=312 size=2340 all=58159 active=3401 piece=who\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=309 size=2360 all=58387 active=3629 piece=‚ñÅfirm\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=306 size=2380 all=58566 active=3808 piece=ton\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=303 size=2400 all=58717 active=3959 piece=‚ñÅpun\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=303 min_freq=110\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=300 size=2420 all=59156 active=3362 piece=‚ñÅrunning\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=296 size=2440 all=59324 active=3530 piece=‚ñÅextr\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=292 size=2460 all=59538 active=3744 piece=‚ñÅune\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=289 size=2480 all=59685 active=3891 piece=‚ñÅbol\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=286 size=2500 all=59828 active=4034 piece=mbling\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=286 min_freq=105\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=282 size=2520 all=60105 active=3265 piece=‚ñÅgate\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=279 size=2540 all=60261 active=3421 piece=‚ñÅjul\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=276 size=2560 all=60449 active=3609 piece=‚ñÅchurch\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=273 size=2580 all=60623 active=3783 piece=ences\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=270 size=2600 all=60757 active=3917 piece=‚ñÅamid\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=270 min_freq=101\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=268 size=2620 all=60945 active=3224 piece=formed\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=265 size=2640 all=61080 active=3359 piece=okhov\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=263 size=2660 all=61180 active=3459 piece=‚ñÅimagine\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=261 size=2680 all=61369 active=3648 piece=‚ñÅimportant\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=257 size=2700 all=61582 active=3861 piece=zz\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=257 min_freq=97\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=254 size=2720 all=61761 active=3226 piece=‚ñÅscarcely\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=251 size=2740 all=61977 active=3442 piece=‚ñÅhistor\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=249 size=2760 all=62199 active=3664 piece=‚ñÅallowed\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=247 size=2780 all=62430 active=3895 piece=‚ñÅbore\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=245 size=2800 all=62523 active=3988 piece=‚ñÅoblig\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=245 min_freq=93\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=242 size=2820 all=62637 active=3235 piece=ested\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=240 size=2840 all=62867 active=3465 piece=levent\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=238 size=2860 all=63000 active=3598 piece=‚ñÅpresented\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=236 size=2880 all=63143 active=3741 piece=ashion\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=233 size=2900 all=63296 active=3894 piece=‚ñÅmoon\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=233 min_freq=90\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=231 size=2920 all=63353 active=3217 piece=‚ñÅsimply\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=228 size=2940 all=63458 active=3322 piece=‚ñÅsacred\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=226 size=2960 all=63631 active=3495 piece=‚ñÅdism\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=224 size=2980 all=63761 active=3625 piece=‚ñÅpi\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=223 size=3000 all=63890 active=3754 piece=‚ñÅfauchelevent\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=222 min_freq=86\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=220 size=3020 all=64103 active=3407 piece=‚ñÅavo\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=218 size=3040 all=64258 active=3562 piece=aste\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=217 size=3060 all=64440 active=3744 piece=‚ñÅshame\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=215 size=3080 all=64573 active=3877 piece=‚ñÅstubb\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=213 size=3100 all=64769 active=4073 piece=lished\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=213 min_freq=83\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=211 size=3120 all=64826 active=3290 piece=orted\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=209 size=3140 all=64969 active=3433 piece=umb\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=208 size=3160 all=65069 active=3533 piece=‚ñÅtelemachus\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=206 size=3180 all=65309 active=3773 piece=olled\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=205 size=3200 all=65397 active=3861 piece=‚ñÅconsidered\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=204 min_freq=81\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=202 size=3220 all=65523 active=3396 piece=‚ñÅeast\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=200 size=3240 all=65657 active=3530 piece=atic\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=199 size=3260 all=65825 active=3698 piece=‚ñÅroof\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=198 size=3280 all=65977 active=3850 piece=‚ñÅprisoner\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=196 size=3300 all=66077 active=3950 piece=‚ñÅfalling\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=195 min_freq=78\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=194 size=3320 all=66241 active=3468 piece=‚ñÅshadows\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=192 size=3340 all=66346 active=3573 piece=‚ñÅlod\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=191 size=3360 all=66402 active=3629 piece=‚ñÅflowers\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=189 size=3380 all=66540 active=3767 piece=‚ñÅaid\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=188 size=3400 all=66639 active=3866 piece=illenormand\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=187 min_freq=76\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=186 size=3420 all=66750 active=3440 piece=iform\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=184 size=3440 all=66864 active=3554 piece=‚ñÅcomr\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=183 size=3460 all=67038 active=3728 piece=‚ñÅdawn\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=182 size=3480 all=67091 active=3781 piece=‚ñÅlanguage\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=180 size=3500 all=67225 active=3915 piece=‚ñÅsigh\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=180 min_freq=73\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=179 size=3520 all=67345 active=3478 piece=‚ñÅsupposed\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=177 size=3540 all=67486 active=3619 piece=‚ñÅvir\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=176 size=3560 all=67608 active=3741 piece=‚ñÅsouth\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=175 size=3580 all=67710 active=3843 piece=‚ñÅgrowing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=173 size=3600 all=67795 active=3928 piece=‚ñÅbid\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=173 min_freq=71\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=172 size=3620 all=67927 active=3518 piece=‚ñÅcler\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=170 size=3640 all=68054 active=3645 piece=‚ñÅham\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=168 size=3660 all=68260 active=3851 piece=crates\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=167 size=3680 all=68399 active=3990 piece=elled\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=166 size=3700 all=68510 active=4101 piece=‚ñÅarrest\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=166 min_freq=69\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=165 size=3720 all=68557 active=3470 piece=‚ñÅwhence\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=163 size=3740 all=68643 active=3556 piece=ky\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=162 size=3760 all=68782 active=3695 piece=cant\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=161 size=3780 all=68900 active=3813 piece=‚ñÅocean\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=160 size=3800 all=69054 active=3967 piece=‚ñÅgoddess\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=160 min_freq=67\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=158 size=3820 all=69196 active=3592 piece=yes\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=158 size=3840 all=69306 active=3702 piece=‚ñÅsurrounded\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=156 size=3860 all=69452 active=3848 piece=seen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=155 size=3880 all=69575 active=3971 piece=‚ñÅgain\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=154 size=3900 all=69682 active=4078 piece=‚ñÅchim\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=154 min_freq=65\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=153 size=3920 all=69791 active=3584 piece=‚ñÅacknow\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=152 size=3940 all=69977 active=3770 piece=‚ñÅfinding\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=151 size=3960 all=70081 active=3874 piece=‚ñÅreader\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=150 size=3980 all=70169 active=3962 piece=‚ñÅfifteen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=149 size=4000 all=70309 active=4102 piece=‚ñÅstick\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=149 min_freq=63\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=148 size=4020 all=70458 active=3659 piece=‚ñÅrough\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=147 size=4040 all=70562 active=3763 piece=‚ñÅcontent\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=146 size=4060 all=70676 active=3877 piece=‚ñÅinterv\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=145 size=4080 all=70798 active=3999 piece=‚ñÅtongue\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=144 size=4100 all=70868 active=4069 piece=‚ñÅproved\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=144 min_freq=61\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=143 size=4120 all=70991 active=3667 piece=‚ñÅlance\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=142 size=4140 all=71071 active=3747 piece=acles\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=141 size=4160 all=71168 active=3844 piece=iance\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=140 size=4180 all=71253 active=3929 piece=oses\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=140 size=4200 all=71317 active=3993 piece=‚ñÅmillions\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=140 min_freq=59\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=139 size=4220 all=71475 active=3722 piece=‚ñÅsacrifice\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=138 size=4240 all=71561 active=3808 piece=‚ñÅproject\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=137 size=4260 all=71776 active=4023 piece=‚ñÅwitch\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=136 size=4280 all=71903 active=4150 piece=‚ñÅcrim\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=136 size=4300 all=71944 active=4191 piece=‚ñÅinformation\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=135 min_freq=57\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=135 size=4320 all=72052 active=3706 piece=‚ñÅdoubtless\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=133 size=4340 all=72173 active=3827 piece=fir\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=133 size=4360 all=72360 active=4014 piece=illery\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=132 size=4380 all=72453 active=4107 piece=‚ñÅbree\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=131 size=4400 all=72597 active=4251 piece=‚ñÅren\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=131 min_freq=56\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=131 size=4420 all=72660 active=3684 piece=‚ñÅdestruction\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=130 size=4440 all=72719 active=3743 piece=‚ñÅlightning\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=128 size=4460 all=72895 active=3919 piece=‚ñÅfulf\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=127 size=4480 all=72965 active=3989 piece=uments\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=126 size=4500 all=73045 active=4069 piece=idable\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=126 min_freq=54\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=125 size=4520 all=73092 active=3697 piece=ih\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=125 size=4540 all=73245 active=3850 piece=‚ñÅmarked\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=124 size=4560 all=73356 active=3961 piece=‚ñÅbodies\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=123 size=4580 all=73487 active=4092 piece=‚ñÅlover\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=122 size=4600 all=73582 active=4187 piece=great\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=122 min_freq=53\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=121 size=4620 all=73704 active=3795 piece=‚ñÅparad\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=120 size=4640 all=73897 active=3988 piece=‚ñÅtale\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=119 size=4660 all=73971 active=4062 piece=iner\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=119 size=4680 all=74041 active=4132 piece=‚ñÅassumed\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=118 size=4700 all=74158 active=4249 piece=ptych\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=118 min_freq=52\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=118 size=4720 all=74226 active=3774 piece=‚ñÅbuilding\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=117 size=4740 all=74312 active=3860 piece=‚ñÅashamed\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=116 size=4760 all=74399 active=3947 piece=ashing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=115 size=4780 all=74441 active=3989 piece=hic\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=115 size=4800 all=74595 active=4143 piece=‚ñÅfeatures\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=115 min_freq=51\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=114 size=4820 all=74674 active=3808 piece=ication\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=113 size=4840 all=74828 active=3962 piece=heard\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=112 size=4860 all=74908 active=4042 piece=ishes\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=112 size=4880 all=74970 active=4104 piece=‚ñÅweeping\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=111 size=4900 all=75069 active=4203 piece=‚ñÅwept\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=111 min_freq=49\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=110 size=4920 all=75121 active=3805 piece=‚ñÅec\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=109 size=4940 all=75179 active=3863 piece=hor\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=109 size=4960 all=75343 active=4027 piece=‚ñÅquitted\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=108 size=4980 all=75416 active=4100 piece=‚ñÅmeat\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=107 size=5000 all=75505 active=4189 piece=‚ñÅiss\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=107 min_freq=48\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=107 size=5020 all=75540 active=3808 piece=‚ñÅcareful\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=106 size=5040 all=75653 active=3921 piece=osure\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=106 size=5060 all=75690 active=3958 piece=‚ñÅwearing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=105 size=5080 all=75738 active=4006 piece=olation\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=104 size=5100 all=75909 active=4177 piece=‚ñÅspl\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=104 min_freq=47\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=104 size=5120 all=76034 active=3912 piece=‚ñÅrulers\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=103 size=5140 all=76032 active=3910 piece=bec\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=103 size=5160 all=76130 active=4008 piece=‚ñÅinvent\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=102 size=5180 all=76192 active=4070 piece=‚ñÅflee\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=102 size=5200 all=76239 active=4117 piece=‚ñÅagreeable\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=102 min_freq=46\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=101 size=5220 all=76365 active=3938 piece=‚ñÅslave\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=100 size=5240 all=76416 active=3989 piece=‚ñÅsole\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=100 size=5260 all=76455 active=4028 piece=‚ñÅconsidering\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=99 size=5280 all=76636 active=4209 piece=‚ñÅbeard\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=99 size=5300 all=76643 active=4216 piece=‚ñÅglorious\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=99 min_freq=45\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=98 size=5320 all=76823 active=4013 piece=‚ñÅapoll\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=97 size=5340 all=76861 active=4051 piece=rious\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=97 size=5360 all=76898 active=4088 piece=‚ñÅdancing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=96 size=5380 all=76951 active=4141 piece=istic\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=96 size=5400 all=77002 active=4192 piece=‚ñÅhastened\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=96 min_freq=44\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=95 size=5420 all=77247 active=4096 piece=inity\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=95 size=5440 all=77321 active=4170 piece=‚ñÅangrily\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=94 size=5460 all=77381 active=4230 piece=‚ñÅbrig\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=94 size=5480 all=77426 active=4275 piece=‚ñÅtyrant\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=93 size=5500 all=77463 active=4312 piece=‚ñÅpole\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=93 min_freq=43\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=93 size=5520 all=77498 active=3905 piece=‚ñÅdistinctly\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=92 size=5540 all=77673 active=4080 piece=‚ñÅheres\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=92 size=5560 all=77731 active=4138 piece=‚ñÅthoroughly\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=91 size=5580 all=77862 active=4269 piece=‚ñÅshake\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=90 size=5600 all=77910 active=4317 piece=ints\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=90 min_freq=42\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=90 size=5620 all=77995 active=3971 piece=‚ñÅviews\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=90 size=5640 all=78009 active=3985 piece=‚ñÅthousands\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=89 size=5660 all=78115 active=4091 piece=‚ñÅagamem\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=88 size=5680 all=78169 active=4145 piece=‚ñÅhs\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=88 size=5700 all=78247 active=4223 piece=‚ñÅbattal\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=88 min_freq=41\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=87 size=5720 all=78330 active=3994 piece=‚ñÅhan\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=87 size=5740 all=78413 active=4077 piece=amation\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=86 size=5760 all=78473 active=4137 piece=omy\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=86 size=5780 all=78690 active=4354 piece=‚ñÅshrie\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=86 size=5800 all=78703 active=4367 piece=‚ñÅconsideration\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=85 min_freq=40\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=85 size=5820 all=78881 active=4114 piece=verend\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=85 size=5840 all=78921 active=4154 piece=‚ñÅdrinking\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=84 size=5860 all=78989 active=4222 piece=cried\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=84 size=5880 all=79037 active=4270 piece=‚ñÅbegged\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=84 size=5900 all=79036 active=4269 piece=‚ñÅinterested\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=84 min_freq=39\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=83 size=5920 all=79268 active=4181 piece=‚ñÅhen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=83 size=5940 all=79342 active=4255 piece=‚ñÅdishon\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=82 size=5960 all=79438 active=4351 piece=foot\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=82 size=5980 all=79510 active=4423 piece=‚ñÅactive\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=82 size=6000 all=79537 active=4450 piece=‚ñÅgrateful\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=82 min_freq=38\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=81 size=6020 all=79614 active=4054 piece=same\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=81 size=6040 all=79697 active=4137 piece=‚ñÅdwell\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=81 size=6060 all=79726 active=4166 piece=‚ñÅvirtues\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=80 size=6080 all=79803 active=4243 piece=‚ñÅfil\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=80 size=6100 all=79825 active=4265 piece=‚ñÅintimate\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=80 min_freq=38\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=79 size=6120 all=79910 active=4077 piece=‚ñÅcult\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=79 size=6140 all=79983 active=4150 piece=‚ñÅinevit\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=79 size=6160 all=79992 active=4159 piece=‚ñÅhousehold\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=78 size=6180 all=80155 active=4322 piece=‚ñÅgore\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=78 size=6200 all=80199 active=4366 piece=‚ñÅunited\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=78 min_freq=37\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=77 size=6220 all=80248 active=4059 piece=‚ñÅaz\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=77 size=6240 all=80325 active=4136 piece=‚ñÅjonah\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=77 size=6260 all=80337 active=4148 piece=‚ñÅthoughtful\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=76 size=6280 all=80393 active=4204 piece=‚ñÅeleven\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=75 size=6300 all=80425 active=4236 piece=lor\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=75 min_freq=36\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=75 size=6320 all=80577 active=4159 piece=looked\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=75 size=6340 all=80619 active=4201 piece=‚ñÅdisdain\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=74 size=6360 all=80636 active=4218 piece=olet\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=74 size=6380 all=80749 active=4331 piece=‚ñÅinher\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=74 size=6400 all=80769 active=4351 piece=‚ñÅcutting\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=74 min_freq=36\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=73 size=6420 all=80901 active=4167 piece=otes\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=73 size=6440 all=80971 active=4237 piece=‚ñÅcoarse\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=73 size=6460 all=80971 active=4237 piece=‚ñÅcollected\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=72 size=6480 all=81075 active=4341 piece=‚ñÅaint\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=72 size=6500 all=81123 active=4389 piece=ceiving\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=72 min_freq=35\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=72 size=6520 all=81131 active=4059 piece=‚ñÅdevotion\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=71 size=6540 all=81187 active=4115 piece=dist\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=71 size=6560 all=81305 active=4233 piece=‚ñÅappar\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=71 size=6580 all=81343 active=4271 piece=‚ñÅcossack\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=71 size=6600 all=81344 active=4272 piece=‚ñÅmultitude\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=71 min_freq=34\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=70 size=6620 all=81401 active=4125 piece=‚ñÅsalt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=70 size=6640 all=81451 active=4175 piece=‚ñÅapplic\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=70 size=6660 all=81455 active=4179 piece=‚ñÅpeppino\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=69 size=6680 all=81519 active=4243 piece=cks\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=69 size=6700 all=81664 active=4388 piece=‚ñÅwarn\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=69 min_freq=34\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=69 size=6720 all=81700 active=4118 piece=‚ñÅfeather\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=68 size=6740 all=81821 active=4239 piece=‚ñÅ25\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=68 size=6760 all=81980 active=4398 piece=‚ñÅjoves\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=68 size=6780 all=81991 active=4409 piece=‚ñÅdecision\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=67 size=6800 all=82111 active=4529 piece=child\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=67 min_freq=33\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=67 size=6820 all=82183 active=4167 piece=‚ñÅwatson\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=67 size=6840 all=82176 active=4160 piece=‚ñÅthnardiers\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=66 size=6860 all=82332 active=4316 piece=‚ñÅugly\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=66 size=6880 all=82376 active=4360 piece=through\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=66 size=6900 all=82401 active=4385 piece=‚ñÅkilling\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=66 min_freq=32\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=66 size=6920 all=82402 active=4122 piece=‚ñÅprocureur\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=65 size=6940 all=82521 active=4241 piece=‚ñÅjac\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=65 size=6960 all=82569 active=4289 piece=‚ñÅruins\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=65 size=6980 all=82610 active=4330 piece=‚ñÅmichael\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=64 size=7000 all=82641 active=4361 piece=comm\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=64 min_freq=32\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=64 size=7020 all=82731 active=4208 piece=‚ñÅexting\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=64 size=7040 all=82755 active=4232 piece=‚ñÅelements\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=63 size=7060 all=82795 active=4272 piece=olom\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=63 size=7080 all=82895 active=4372 piece=‚ñÅboldly\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=63 size=7100 all=82906 active=4383 piece=‚ñÅpiercing\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=63 min_freq=31\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=62 size=7120 all=82971 active=4211 piece=‚ñÅsne\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=62 size=7140 all=83017 active=4257 piece=‚ñÅtkhon\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=62 size=7160 all=83038 active=4278 piece=‚ñÅbonapart\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=61 size=7180 all=83160 active=4400 piece=‚ñÅflu\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=61 size=7200 all=83249 active=4489 piece=liness\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=61 min_freq=31\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=61 size=7220 all=83295 active=4188 piece=‚ñÅrelate\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=61 size=7240 all=83288 active=4181 piece=‚ñÅinvestig\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=60 size=7260 all=83371 active=4264 piece=vts\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=60 size=7280 all=83506 active=4399 piece=‚ñÅflut\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=60 size=7300 all=83546 active=4439 piece=‚ñÅusing\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=60 min_freq=30\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=60 size=7320 all=83575 active=4207 piece=‚ñÅinterval\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=59 size=7340 all=83637 active=4269 piece=‚ñÅrou\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=59 size=7360 all=83715 active=4347 piece=‚ñÅrights\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=59 size=7380 all=83727 active=4359 piece=‚ñÅsciences\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=58 size=7400 all=83874 active=4506 piece=‚ñÅunp\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=58 min_freq=30\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=58 size=7420 all=83949 active=4256 piece=ruption\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=58 size=7440 all=83958 active=4265 piece=‚ñÅelapsed\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=58 size=7460 all=83954 active=4261 piece=‚ñÅpractical\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=57 size=7480 all=84075 active=4382 piece=‚ñÅhem\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=57 size=7500 all=84176 active=4483 piece=‚ñÅachae\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=57 min_freq=29\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=57 size=7520 all=84218 active=4249 piece=‚ñÅartist\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=57 size=7540 all=84220 active=4251 piece=‚ñÅsmaller\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=57 size=7560 all=84213 active=4244 piece=‚ñÅdownstairs\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=56 size=7580 all=84358 active=4389 piece=‚ñÅwag\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=56 size=7600 all=84466 active=4497 piece=things\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=56 min_freq=29\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=56 size=7620 all=84498 active=4252 piece=‚ñÅpaying\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=56 size=7640 all=84506 active=4260 piece=‚ñÅconceive\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=55 size=7660 all=84579 active=4333 piece=idel\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=55 size=7680 all=84658 active=4412 piece=‚ñÅupro\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=55 size=7700 all=84702 active=4456 piece=‚ñÅgallery\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=55 min_freq=28\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=55 size=7720 all=84700 active=4234 piece=‚ñÅphysician\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=54 size=7740 all=84784 active=4318 piece=iners\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=54 size=7760 all=84852 active=4386 piece=‚ñÅaided\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=54 size=7780 all=84870 active=4404 piece=‚ñÅwarmth\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=54 size=7800 all=84869 active=4403 piece=‚ñÅproperly\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=54 min_freq=28\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=53 size=7820 all=84876 active=4251 piece=sl\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=53 size=7840 all=85019 active=4394 piece=‚ñÅgale\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=53 size=7860 all=85074 active=4449 piece=‚ñÅbowing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=53 size=7880 all=85090 active=4465 piece=‚ñÅconsist\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=52 size=7900 all=85093 active=4468 piece=aul\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=52 min_freq=27\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=52 size=7920 all=85188 active=4335 piece=‚ñÅbast\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=52 size=7940 all=85249 active=4396 piece=‚ñÅacting\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=52 size=7960 all=85252 active=4399 piece=‚ñÅgardens\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=52 size=7980 all=85249 active=4396 piece=‚ñÅarguments\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=51 size=8000 all=85253 active=4400 piece=ims\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=51 min_freq=27\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=51 size=8020 all=85381 active=4376 piece=‚ñÅdorm\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=51 size=8040 all=85425 active=4420 piece=‚ñÅpanic\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=51 size=8060 all=85461 active=4456 piece=‚ñÅsnatch\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=51 size=8080 all=85461 active=4456 piece=‚ñÅcustomary\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=50 size=8100 all=85550 active=4545 piece=six\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=50 min_freq=26\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=50 size=8120 all=85700 active=4418 piece=‚ñÅoutl\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=50 size=8140 all=85744 active=4462 piece=‚ñÅjordan\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=50 size=8160 all=85747 active=4465 piece=‚ñÅcontains\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=49 size=8180 all=85732 active=4450 piece=ano\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=49 size=8200 all=85892 active=4610 piece=‚ñÅpyl\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=49 min_freq=26\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=49 size=8220 all=85946 active=4343 piece=‚ñÅsout\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=49 size=8240 all=85971 active=4368 piece=‚ñÅoppose\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=49 size=8260 all=85974 active=4371 piece=‚ñÅreverse\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=49 size=8280 all=85979 active=4376 piece=ÔøΩÔøΩÔøΩtemperance\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=48 size=8300 all=86084 active=4481 piece=‚ñÅsed\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=48 min_freq=26\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=48 size=8320 all=86169 active=4373 piece=‚ñÅterr\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=48 size=8340 all=86190 active=4394 piece=‚ñÅvicom\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=48 size=8360 all=86213 active=4417 piece=atisfied\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=48 size=8380 all=86206 active=4410 piece=‚ñÅdrooping\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=48 size=8400 all=86199 active=4403 piece=‚ñÅsurprising\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=48 min_freq=25\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=47 size=8420 all=86273 active=4383 piece=bacco\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=47 size=8440 all=86350 active=4460 piece=indeed\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=47 size=8460 all=86394 active=4504 piece=‚ñÅscand\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=47 size=8480 all=86399 active=4509 piece=‚ñÅcarries\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=47 size=8500 all=86398 active=4508 piece=‚ñÅencourage\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=47 min_freq=25\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=46 size=8520 all=86488 active=4409 piece=‚ñÅyan\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=46 size=8540 all=86562 active=4483 piece=estern\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=46 size=8560 all=86595 active=4516 piece=itively\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=46 size=8580 all=86619 active=4540 piece=‚ñÅrepent\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=46 size=8600 all=86630 active=4551 piece=‚ñÅsatisfy\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=46 min_freq=24\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=46 size=8620 all=86630 active=4332 piece=‚ñÅatmosphere\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=45 size=8640 all=86732 active=4434 piece=soon\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=45 size=8660 all=86847 active=4549 piece=‚ñÅhing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=45 size=8680 all=86891 active=4593 piece=‚ñÅdeaths\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=45 size=8700 all=86890 active=4592 piece=‚ñÅparalle\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=45 min_freq=24\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=45 size=8720 all=86895 active=4347 piece=‚ñÅretained\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=45 size=8740 all=86877 active=4329 piece=‚ñÅstammered\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=44 size=8760 all=86948 active=4400 piece=sun\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=44 size=8780 all=87048 active=4500 piece=‚ñÅfund\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=44 size=8800 all=87100 active=4552 piece=‚ñÅgrotto\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=44 min_freq=24\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=44 size=8820 all=87100 active=4354 piece=‚ñÅweighed\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=44 size=8840 all=87084 active=4338 piece=‚ñÅswineherd\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43 size=8860 all=87131 active=4385 piece=‚ñÅrh\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43 size=8880 all=87262 active=4516 piece=‚ñÅbite\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43 size=8900 all=87340 active=4594 piece=myself\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=43 min_freq=23\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43 size=8920 all=87354 active=4381 piece=‚ñÅbrujon\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43 size=8940 all=87354 active=4381 piece=‚ñÅbarclay\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43 size=8960 all=87350 active=4377 piece=iethepooh\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43 size=8980 all=87342 active=4369 piece=‚ñÅenclosure\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=42 size=9000 all=87379 active=4406 piece=nut\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=42 min_freq=23\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=42 size=9020 all=87518 active=4499 piece=ieces\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=42 size=9040 all=87598 active=4579 piece=urable\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=42 size=9060 all=87617 active=4598 piece=‚ñÅfulfil\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=42 size=9080 all=87614 active=4595 piece=‚ñÅpuzzled\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=42 size=9100 all=87601 active=4582 piece=‚ñÅproposal\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=42 min_freq=23\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=42 size=9120 all=87599 active=4379 piece=‚ñÅregimental\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41 size=9140 all=87738 active=4518 piece=dont\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41 size=9160 all=87841 active=4621 piece=monte\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41 size=9180 all=87901 active=4681 piece=heaven\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41 size=9200 all=87944 active=4724 piece=renched\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=41 min_freq=22\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41 size=9220 all=87965 active=4414 piece=‚ñÅvisits\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41 size=9240 all=87976 active=4425 piece=‚ñÅstrides\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41 size=9260 all=87972 active=4421 piece=‚ñÅvigorous\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41 size=9280 all=87961 active=4410 piece=‚ñÅexplaining\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40 size=9300 all=88042 active=4491 piece=gree\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=40 min_freq=22\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40 size=9320 all=88093 active=4450 piece=‚ñÅmice\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40 size=9340 all=88107 active=4464 piece=‚ñÅshaft\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40 size=9360 all=88118 active=4475 piece=‚ñÅrascal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40 size=9380 all=88116 active=4473 piece=‚ñÅsubsequ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40 size=9400 all=88113 active=4470 piece=understand\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=40 min_freq=22\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40 size=9420 all=88107 active=4397 piece=‚ñÅpeculiarly\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=39 size=9440 all=88170 active=4460 piece=beau\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=39 size=9460 all=88258 active=4548 piece=‚ñÅscan\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=39 size=9480 all=88306 active=4596 piece=‚ñÅcreep\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=39 size=9500 all=88334 active=4624 piece=‚ñÅmedium\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=39 min_freq=21\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=39 size=9520 all=88336 active=4418 piece=‚ñÅmuskets\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=39 size=9540 all=88323 active=4405 piece=‚ñÅenergetic\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=9560 all=88343 active=4425 piece=sis\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=9580 all=88467 active=4549 piece=odule\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=9600 all=88517 active=4599 piece=‚ñÅtrod\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=38 min_freq=21\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=9620 all=88536 active=4443 piece=uscript\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=9640 all=88543 active=4450 piece=‚ñÅviewed\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=9660 all=88554 active=4461 piece=‚ñÅteacher\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=9680 all=88545 active=4452 piece=‚ñÅingenious\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=9700 all=88611 active=4518 piece=ago\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=37 min_freq=21\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=9720 all=88737 active=4550 piece=‚ñÅmob\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=9740 all=88807 active=4620 piece=‚ñÅharv\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=9760 all=88876 active=4689 piece=inking\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=9780 all=88912 active=4725 piece=‚ñÅarises\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=9800 all=88921 active=4734 piece=‚ñÅsubord\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=37 min_freq=21\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=9820 all=88918 active=4440 piece=‚ñÅpensive\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=9840 all=88911 active=4433 piece=‚ñÅnorthern\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=9860 all=88893 active=4415 piece=‚ñÅtreatment\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36 size=9880 all=88942 active=4464 piece=sal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36 size=9900 all=89079 active=4601 piece=‚ñÅlug\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=36 min_freq=20\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36 size=9920 all=89152 active=4524 piece=‚ñÅnour\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36 size=9940 all=89205 active=4577 piece=aration\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: tokenizer.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: tokenizer.vocab\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad Token ID: 3\n",
      "Loaded 39557 text entries from train.jsonl. Total length: 14673121 characters\n",
      "Loaded 9890 text entries from test.jsonl. Total length: 3684340 characters\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "###############################################################################\n",
    "# Main Training and Evaluation Pipeline\n",
    "###############################################################################\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to train, evaluate, and compare the language models.\n",
    "    \n",
    "    This function performs the following steps:\n",
    "      1. Sets hyperparameters and file paths.\n",
    "      2. Prepares the tokenizer (training it if needed).\n",
    "      3. Loads and tokenizes training and validation datasets.\n",
    "      4. Builds fixed-length sequences and creates DataLoaders.\n",
    "      5. Initializes the RNN, LSTM, and Transformer models.\n",
    "      6. Trains each model with early stopping, gradient clipping, and a cosine scheduler.\n",
    "      7. Evaluates each model using perplexity, token accuracy, and BLEU score.\n",
    "      8. Generates sample text for a fixed prompt.\n",
    "      9. Saves model parameters and displays performance comparisons through plots.\n",
    "    \"\"\"\n",
    "    global_start = time.time()\n",
    "\n",
    "    # ------------------ Hyperparameters ------------------\n",
    "    vocab_size = 10000          # Vocabulary size for tokenizer\n",
    "    embed_dim = 256             # Embedding dimension for tokens\n",
    "    hidden_dim = 128            # Hidden dimension for RNN/LSTM and transformer feedforward\n",
    "    num_layers = 2              # Number of layers in RNN/LSTM/Transformer encoder\n",
    "    num_heads = 8               # Number of attention heads in Transformer\n",
    "    max_seq_length = 128         # Input sequence length (without EOS token)\n",
    "    batch_size = 256            # Training batch size\n",
    "    num_epochs = 30             # Maximum number of epochs for training\n",
    "    learning_rate = 5e-4        # Initial learning rate\n",
    "    dropout_rate = 0.3          # Dropout rate for Transformer positional encoding and encoder layers\n",
    "    weight_decay = 1e-4         # Weight decay for optimizer regularization\n",
    "    pad_token_id = 3            # Token ID for padding (should match tokenizer's setting)\n",
    "\n",
    "    # ------------------ File Paths ------------------\n",
    "    # Update these paths as needed.\n",
    "    train_file = \"train.jsonl\"\n",
    "    test_file = \"test.jsonl\"\n",
    "    \n",
    "    if not os.path.exists(train_file) or not os.path.exists(test_file):\n",
    "        raise FileNotFoundError(\"train.jsonl and/or test.jsonl not found.\")\n",
    "    \n",
    "    # ------------------ Prepare Training Text for Tokenizer ------------------\n",
    "    tokenizer_training_file = \"train.jsonl\"\n",
    "    if not os.path.exists(tokenizer_training_file):\n",
    "        texts = []\n",
    "        with open(train_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    obj = json.loads(line)\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "                prompt = obj.get(\"prompt\", \"\")\n",
    "                completion = obj.get(\"completion\", \"\")\n",
    "                text = (prompt + \" \" + completion).strip()\n",
    "                if text:\n",
    "                    texts.append(text)\n",
    "        # Combine all text entries into one large file.\n",
    "        combined_text = \"\\n\".join(texts)\n",
    "        with open(tokenizer_training_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(combined_text)\n",
    "\n",
    "    # ------------------ Tokenizer Preparation ------------------\n",
    "    sp = train_tokenizer_if_needed(tokenizer_model_prefix=\"tokenizer\", vocab_size=vocab_size, training_text_file=tokenizer_training_file)\n",
    "    # Use the pad token id from SentencePiece to ensure consistency\n",
    "    pad_token_id = sp.pad_id()\n",
    "    print(\"Pad Token ID:\", pad_token_id)\n",
    "\n",
    "    # ------------------ Load and Tokenize Datasets ------------------\n",
    "    train_tokens = load_and_tokenize(train_file, sp)\n",
    "    val_tokens = load_and_tokenize(test_file, sp)\n",
    "\n",
    "    # ------------------ Build Fixed-Length Token Sequences ------------------\n",
    "    train_seqs = build_sequences(train_tokens, max_seq_length)\n",
    "    val_seqs = build_sequences(val_tokens, max_seq_length)\n",
    "    print(f\"Number of train tokens: {len(train_tokens)}\")\n",
    "    print(f\"Number of val tokens: {len(val_tokens)}\")\n",
    "    print(f\"Number of training sequences: {len(train_seqs)}\")\n",
    "    print(f\"Number of validation sequences: {len(val_seqs)}\")\n",
    "\n",
    "    # ------------------ Create Dataset Objects and DataLoaders ------------------\n",
    "    train_dataset = LanguageModelDataset(train_seqs, max_seq_length)\n",
    "    val_dataset = LanguageModelDataset(val_seqs, max_seq_length)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                              num_workers=0, pin_memory=True if device.type == \"cuda\" else False)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size,\n",
    "                            num_workers=0, pin_memory=True if device.type == \"cuda\" else False)\n",
    "\n",
    "    # ------------------ Initialize Models ------------------\n",
    "    models = {\n",
    "    \"RNN\": RNNLanguageModel(vocab_size, embed_dim, hidden_dim, num_layers, dropout_rate=dropout_rate),\n",
    "    \"LSTM\": LSTMLanguageModel(vocab_size, embed_dim, hidden_dim, num_layers, dropout_rate=dropout_rate),\n",
    "    \"Transformer\": TransformerLanguageModel(vocab_size, embed_dim, num_heads, hidden_dim, num_layers, max_seq_length, dropout=dropout_rate)\n",
    "    }\n",
    "\n",
    "    model_results = {}  # Dictionary to hold evaluation metrics for each model\n",
    "\n",
    "    # ------------------ Train, Evaluate and Compare Models ------------------\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n--- Training {name} Model ---\")\n",
    "        model.to(device)\n",
    "        # Use CrossEntropyLoss ignoring the padding token.\n",
    "        criterion = nn.CrossEntropyLoss(ignore_index=pad_token_id)\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        # Using a cosine annealing scheduler that adjusts the learning rate over epochs.\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-5)\n",
    "        \n",
    "        # Train model and record time.\n",
    "        model_start_time = time.time()\n",
    "        train_losses, val_losses = train_model(model, train_loader, val_loader, num_epochs,\n",
    "                                                criterion, optimizer, scheduler, device, patience=5)\n",
    "        training_time = time.time() - model_start_time\n",
    "        print(f\"Total training time for {name}: {training_time:.2f} seconds\")\n",
    "        \n",
    "        # Plot loss curves with detailed annotations.\n",
    "        plot_loss_curve(train_losses, val_losses, name)\n",
    "        \n",
    "        # Evaluate model on validation set.\n",
    "        val_loss = evaluate_model(model, val_loader, criterion, device)\n",
    "        perplexity = compute_perplexity(val_loss)\n",
    "        token_accuracy = compute_token_accuracy(model, val_loader, device, pad_token_id) * 100\n",
    "        \n",
    "        # Compute BLEU score on a random sample from validation dataset.\n",
    "    if len(val_dataset) > 0:\n",
    "        sample_idx = random.randint(0, len(val_dataset) - 1)\n",
    "        sample_input, sample_target = val_dataset[sample_idx]\n",
    "        prompt_text = sp.decode(sample_input.tolist())\n",
    "        reference_text = sp.decode(sample_target.tolist())\n",
    "        generated_text = model.prompt(sp, prompt_text, max_length=128, temperature=1.0, pad_token_id=pad_token_id)\n",
    "        bleu = compute_bleu(reference_text, generated_text)\n",
    "    else:\n",
    "        bleu = 0.0\n",
    "        \n",
    "        print(f\"{name} | Perplexity: {perplexity:.2f} | Token Accuracy: {token_accuracy:.2f}% | BLEU: {bleu:.4f}\")\n",
    "        \n",
    "        # Generate sample output for a fixed prompt.\n",
    "        fixed_prompt = \"Which do you prefer? Dogs or cats?\"\n",
    "        sample_output = model.prompt(sp, fixed_prompt, max_length=128, temperature=1.0)\n",
    "        print(\"Sample generated output:\", sample_output)\n",
    "        \n",
    "        # Save the trained model state.\n",
    "        torch.save(model.state_dict(), f\"{name}_model.pt\")\n",
    "        print(f\"{name} model saved as {name}_model.pt\")\n",
    "        \n",
    "        # Store evaluation metrics for later comparison.\n",
    "        model_results[name] = {\n",
    "            \"ValLoss\": val_loss,\n",
    "            \"Perplexity\": perplexity,\n",
    "            \"Token Accuracy (%)\": token_accuracy,\n",
    "            \"BLEU Score\": bleu,\n",
    "            \"Training Time (s)\": training_time\n",
    "        }\n",
    "    \n",
    "    # ------------------ Compare Model Performance ------------------\n",
    "    print(\"\\n--- Model Performance Summary ---\")\n",
    "    header = f\"{'Model':<15} {'Perplexity':<12} {'Token Accuracy (%)':<20} {'BLEU Score':<12} {'Train Time (s)':<15}\"\n",
    "    print(header)\n",
    "    for model_name, metrics in model_results.items():\n",
    "        print(f\"{model_name:<15} {metrics['Perplexity']:<12.2f} {metrics['Token Accuracy (%)']:<20.2f} \"\n",
    "              f\"{metrics['BLEU Score']:<12.4f} {metrics['Training Time (s)']:<15.2f}\")\n",
    "    \n",
    "    # Create comparative bar plots.\n",
    "    model_names = list(model_results.keys())\n",
    "    perplexities = [model_results[m][\"Perplexity\"] for m in model_names]\n",
    "    accuracies = [model_results[m][\"Token Accuracy (%)\"] for m in model_names]\n",
    "    bleu_scores = [model_results[m][\"BLEU Score\"] for m in model_names]\n",
    "    train_times = [model_results[m][\"Training Time (s)\"] for m in model_names]\n",
    "    \n",
    "    x = np.arange(len(model_names))\n",
    "    width = 0.18\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    \n",
    "    axs[0, 0].bar(x, perplexities, width, color=\"skyblue\")\n",
    "    axs[0, 0].set_title(\"Perplexity\")\n",
    "    axs[0, 0].set_xticks(x)\n",
    "    axs[0, 0].set_xticklabels(model_names)\n",
    "    \n",
    "    axs[0, 1].bar(x, accuracies, width, color=\"lightgreen\")\n",
    "    axs[0, 1].set_title(\"Token Accuracy (%)\")\n",
    "    axs[0, 1].set_xticks(x)\n",
    "    axs[0, 1].set_xticklabels(model_names)\n",
    "    \n",
    "    axs[1, 0].bar(x, bleu_scores, width, color=\"salmon\")\n",
    "    axs[1, 0].set_title(\"BLEU Score\")\n",
    "    axs[1, 0].set_xticks(x)\n",
    "    axs[1, 0].set_xticklabels(model_names)\n",
    "    \n",
    "    axs[1, 1].bar(x, train_times, width, color=\"plum\")\n",
    "    axs[1, 1].set_title(\"Training Time (s)\")\n",
    "    axs[1, 1].set_xticks(x)\n",
    "    axs[1, 1].set_xticklabels(model_names)\n",
    "    \n",
    "    plt.suptitle(\"Model Performance and Computational Requirements Comparison\", fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.savefig(\"model_comparison.png\", dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    total_time = time.time() - global_start\n",
    "    print(f\"\\nTotal elapsed time: {total_time:.2f} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Pad Token ID: 3\n",
      "Loaded 39557 entries from train.jsonl. Total length: 14673121 characters.\n",
      "Loaded 9890 entries from test.jsonl. Total length: 3684340 characters.\n",
      "Created 3413350 sequences of length 129.\n",
      "Created 858089 sequences of length 129.\n",
      "Dataset initialized with 3413350 samples.\n",
      "Dataset initialized with 858089 samples.\n",
      "Positional encoding created with shape: torch.Size([1, 128, 256])\n",
      "\n",
      "--- Training RNN Model ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 423\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTotal elapsed time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 423\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[13], line 394\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    391\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mCosineAnnealingLR(optimizer, T_max\u001b[38;5;241m=\u001b[39mnum_epochs, eta_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n\u001b[1;32m    393\u001b[0m start_model \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 394\u001b[0m train_losses, val_losses \u001b[38;5;241m=\u001b[39m train_model(model, train_loader, val_loader, num_epochs,\n\u001b[1;32m    395\u001b[0m                                         criterion, optimizer, scheduler, device, pad_token_id, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    396\u001b[0m training_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_model\n\u001b[1;32m    397\u001b[0m plot_loss_curve(train_losses, val_losses, name)\n",
      "Cell \u001b[0;32mIn[13], line 262\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, num_epochs, criterion, optimizer, scheduler, device, pad_token_id, patience)\u001b[0m\n\u001b[1;32m    260\u001b[0m inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    261\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 262\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m    263\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, outputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), targets\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    264\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[13], line 149\u001b[0m, in \u001b[0;36mRNNLanguageModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    147\u001b[0m embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)  \u001b[38;5;66;03m# [batch_size, seq_length, embed_dim]\u001b[39;00m\n\u001b[1;32m    148\u001b[0m output, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn(embeds)  \u001b[38;5;66;03m# [batch_size, seq_length, hidden_dim]\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(output)      \u001b[38;5;66;03m# [batch_size, seq_length, vocab_size]\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import math\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sentencepiece as spm  # Install via pip if needed: pip install sentencepiece\n",
    "\n",
    "# Set the device for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "###############################################################################\n",
    "# Positional Encoding Module (used by the Transformer model)\n",
    "###############################################################################\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Computes sinusoidal positional encodings as described in \n",
    "    \"Attention is All You Need.\" These encodings inject information about \n",
    "    token position into embeddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim, max_len=512, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        pos_enc = torch.zeros(max_len, embed_dim)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, embed_dim, 2, dtype=torch.float) *\n",
    "                             -(math.log(10000.0) / embed_dim))\n",
    "        pos_enc[:, 0::2] = torch.sin(position * div_term)\n",
    "        pos_enc[:, 1::2] = torch.cos(position * div_term)\n",
    "        pos_enc = pos_enc.unsqueeze(0)  # shape: [1, max_len, embed_dim]\n",
    "        self.register_buffer(\"pos_enc\", pos_enc)\n",
    "        print(f\"Positional encoding created with shape: {self.pos_enc.shape}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, seq_length, embed_dim]\n",
    "        seq_len = x.size(1)\n",
    "        x = x + self.pos_enc[:, :seq_len]\n",
    "        return self.dropout(x)\n",
    "\n",
    "###############################################################################\n",
    "# Helper Functions: Mask Generation, Tokenizer Utilities, and Sequence Builder\n",
    "###############################################################################\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    \"\"\"\n",
    "    Generates a causal mask for transformer models.\n",
    "    Returns a [sz, sz] tensor with -inf in upper triangle and zeros elsewhere.\n",
    "    \"\"\"\n",
    "    mask = torch.triu(torch.ones(sz, sz), diagonal=1)\n",
    "    mask = mask.masked_fill(mask == 1, float('-inf'))\n",
    "    return mask\n",
    "\n",
    "def train_tokenizer_if_needed(tokenizer_model_prefix=\"tokenizer\", vocab_size=10000, training_text_file=\"merged_corpus.txt\"):\n",
    "    \"\"\"\n",
    "    Trains a SentencePiece tokenizer if the model file does not exist.\n",
    "    \"\"\"\n",
    "    model_file = f\"{tokenizer_model_prefix}.model\"\n",
    "    if not os.path.exists(model_file):\n",
    "        print(\"Training tokenizer...\")\n",
    "        with open(training_text_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            training_text = f.read()\n",
    "        with open(\"temp_training.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(training_text)\n",
    "        train_command = f\"--input=temp_training.txt --model_prefix={tokenizer_model_prefix} --vocab_size={vocab_size} --model_type=bpe --character_coverage=1.0 --pad_id=3 --pad_piece=[PAD]\"\n",
    "        print(\"Training command:\", train_command)\n",
    "        spm.SentencePieceTrainer.train(train_command)\n",
    "        os.remove(\"temp_training.txt\")\n",
    "    sp = spm.SentencePieceProcessor(model_file=model_file)\n",
    "    return sp\n",
    "\n",
    "def load_and_tokenize(file_path, sp):\n",
    "    \"\"\"\n",
    "    Loads a JSONL file and tokenizes each entry.\n",
    "    Each JSON object must have the keys \"prompt\" and \"completion.\"\n",
    "    \"\"\"\n",
    "    texts = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                obj = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "            prompt = obj.get(\"prompt\", \"\")\n",
    "            completion = obj.get(\"completion\", \"\")\n",
    "            text = (prompt + \" \" + completion).strip()\n",
    "            if text:\n",
    "                texts.append(text)\n",
    "    combined = \"\\n\".join(texts)\n",
    "    print(f\"Loaded {len(texts)} entries from {file_path}. Total length: {len(combined)} characters.\")\n",
    "    return sp.encode(combined, out_type=int)\n",
    "\n",
    "def build_sequences(token_ids, seq_length):\n",
    "    \"\"\"\n",
    "    Builds overlapping sequences from token IDs.\n",
    "    Each sequence is of length (seq_length+1) to allow input/target pairing.\n",
    "    \"\"\"\n",
    "    sequences = [token_ids[i:i+seq_length+1] for i in range(len(token_ids)-seq_length)]\n",
    "    print(f\"Created {len(sequences)} sequences of length {seq_length+1}.\")\n",
    "    return sequences\n",
    "\n",
    "###############################################################################\n",
    "# Custom Dataset for Language Modeling\n",
    "###############################################################################\n",
    "class LanguageModelDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Constructs a dataset for language modeling where each sample is a tuple:\n",
    "      (input_tokens, target_tokens)\n",
    "    The target tokens are the input tokens shifted one position.\n",
    "    \"\"\"\n",
    "    def __init__(self, sequences, seq_length):\n",
    "        # Only include sequences with exactly seq_length+1 tokens\n",
    "        self.samples = [(seq[:-1], seq[1:]) for seq in sequences if len(seq)==seq_length+1]\n",
    "        print(f\"Dataset initialized with {len(self.samples)} samples.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inp, target = self.samples[idx]\n",
    "        return torch.tensor(inp, dtype=torch.long), torch.tensor(target, dtype=torch.long)\n",
    "\n",
    "###############################################################################\n",
    "# Model Definitions: RNN, LSTM, and Transformer\n",
    "###############################################################################\n",
    "class RNNLanguageModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Vanilla RNN-based language model.\n",
    "    \n",
    "    Architecture:\n",
    "      - Embedding layer.\n",
    "      - One or more RNN layers.\n",
    "      - Fully-connected layer to produce token logits.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn = nn.RNN(embed_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, seq_length]\n",
    "        embeds = self.embedding(x)  # [batch_size, seq_length, embed_dim]\n",
    "        output, _ = self.rnn(embeds)  # [batch_size, seq_length, hidden_dim]\n",
    "        logits = self.fc(output)      # [batch_size, seq_length, vocab_size]\n",
    "        return logits\n",
    "\n",
    "    def prompt(self, tokenizer, prompt_text, max_length=128, temperature=1.0, pad_token_id=3):\n",
    "        return generate_text(self, tokenizer, prompt_text, max_length, temperature, pad_token_id)\n",
    "\n",
    "class LSTMLanguageModel(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM-based language model.\n",
    "    \n",
    "    Architecture:\n",
    "      - Embedding layer.\n",
    "      - One or more LSTM layers.\n",
    "      - Fully-connected layer to output token probabilities.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, seq_length]\n",
    "        embeds = self.embedding(x)  # [batch_size, seq_length, embed_dim]\n",
    "        output, _ = self.lstm(embeds)  # [batch_size, seq_length, hidden_dim]\n",
    "        logits = self.fc(output)       # [batch_size, seq_length, vocab_size]\n",
    "        return logits\n",
    "\n",
    "    def prompt(self, tokenizer, prompt_text, max_length=128, temperature=1.0, pad_token_id=3):\n",
    "        return generate_text(self, tokenizer, prompt_text, max_length, temperature, pad_token_id)\n",
    "\n",
    "class TransformerLanguageModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer-based language model.\n",
    "    \n",
    "    Architecture:\n",
    "      - Embedding layer followed by positional encoding.\n",
    "      - Transformer encoder to capture long-range dependencies.\n",
    "      - Fully-connected output layer producing vocabulary logits.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, hidden_dim, num_layers, max_seq_length, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.pos_encoder = PositionalEncoding(embed_dim, max_len=max_seq_length, dropout=dropout)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads,\n",
    "                                                   dim_feedforward=hidden_dim, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.fc = nn.Linear(embed_dim, vocab_size)\n",
    "    \n",
    "    def forward(self, x, src_mask=None, src_key_padding_mask=None):\n",
    "        # x: [batch_size, seq_length]\n",
    "        embeds = self.embedding(x)  # [batch_size, seq_length, embed_dim]\n",
    "        encoded = self.pos_encoder(embeds)\n",
    "        # Transformer expects input shape [seq_length, batch_size, embed_dim]\n",
    "        encoded = encoded.transpose(0, 1)\n",
    "        if src_mask is None:\n",
    "            seq_len = x.size(1)\n",
    "            src_mask = generate_square_subsequent_mask(seq_len).to(x.device)\n",
    "        transformer_out = self.transformer_encoder(encoded, mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
    "        # In case the transformer encoder returns a tuple, extract the tensor.\n",
    "        if isinstance(transformer_out, tuple):\n",
    "            transformer_out = transformer_out[0]\n",
    "        transformer_out = transformer_out.transpose(0, 1)  # [batch_size, seq_length, embed_dim]\n",
    "        logits = self.fc(transformer_out)\n",
    "        return logits\n",
    "\n",
    "    def prompt(self, tokenizer, prompt_text, max_length=128, temperature=1.0, pad_token_id=3):\n",
    "        return generate_text(self, tokenizer, prompt_text, max_length, temperature, pad_token_id)\n",
    "\n",
    "###############################################################################\n",
    "# Text Generation, Training, and Evaluation Functions\n",
    "###############################################################################\n",
    "def generate_text(model, tokenizer, prompt_text, max_length=128, temperature=1.0, pad_token_id=3):\n",
    "    \"\"\"\n",
    "    Autoregressively generates text from the model given a prompt.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    token_ids = tokenizer.encode(prompt_text, out_type=int)\n",
    "    generated = token_ids.copy()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            input_ids = torch.tensor([generated], dtype=torch.long, device=next(model.parameters()).device)\n",
    "            logits = model(input_ids)\n",
    "            # Use the logits for the last time step.\n",
    "            next_logits = logits[0, -1, :]\n",
    "            if temperature < 1e-5:\n",
    "                next_token = torch.argmax(next_logits).item()\n",
    "            else:\n",
    "                scaled_logits = next_logits / temperature\n",
    "                probs = torch.softmax(scaled_logits, dim=0)\n",
    "                next_token = torch.multinomial(probs, num_samples=1).item()\n",
    "            generated.append(next_token)\n",
    "            if next_token == pad_token_id:\n",
    "                break\n",
    "    return tokenizer.decode(generated)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs, criterion, optimizer, scheduler, device, pad_token_id, patience=5):\n",
    "    \"\"\"\n",
    "    Trains the model for a maximum of num_epochs, using early stopping based on validation loss.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "    best_state = None\n",
    "    epochs_no_improve = 0\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        start_time = time.time()\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.view(-1, outputs.size(-1)), targets.view(-1))\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        avg_train_loss = epoch_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        epoch_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs.view(-1, outputs.size(-1)), targets.view(-1))\n",
    "                epoch_val_loss += loss.item()\n",
    "        avg_val_loss = epoch_val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        scheduler.step()\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"Epoch {epoch} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Time: {elapsed:.2f}s\")\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(\"Early stopping triggered. Restoring best model state.\")\n",
    "                model.load_state_dict(best_state)\n",
    "                break\n",
    "    return train_losses, val_losses\n",
    "\n",
    "def evaluate_model(model, data_loader, criterion, device, pad_token_id):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the provided data loader.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.view(-1, outputs.size(-1)), targets.view(-1))\n",
    "            total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    print(\"Evaluation loss:\", avg_loss)\n",
    "    return avg_loss\n",
    "\n",
    "def plot_loss_curve(train_losses, val_losses, model_name):\n",
    "    \"\"\"\n",
    "    Plots and saves the loss curves.\n",
    "    \"\"\"\n",
    "    epochs = range(1, len(train_losses)+1)\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(epochs, train_losses, label=\"Train Loss\", marker='o')\n",
    "    plt.plot(epochs, val_losses, label=\"Validation Loss\", marker='s')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(f\"{model_name} Loss Curve\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{model_name}_loss.png\", dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"Loss curve saved as {model_name}_loss.png\")\n",
    "\n",
    "###############################################################################\n",
    "# Main Training and Evaluation Pipeline\n",
    "###############################################################################\n",
    "def main():\n",
    "    global_start = time.time()\n",
    "    \n",
    "    # Hyperparameters and file paths ‚Äì adjust these as needed.\n",
    "    vocab_size = 10000\n",
    "    embed_dim = 256\n",
    "    hidden_dim = 128\n",
    "    num_layers = 2\n",
    "    num_heads = 8\n",
    "    max_seq_length = 128  # Sequence length (excluding EOS token)\n",
    "    batch_size = 256\n",
    "    num_epochs = 30\n",
    "    learning_rate = 5e-4\n",
    "    dropout_rate = 0.3\n",
    "    weight_decay = 1e-4\n",
    "    pad_token = 3  # This should match the tokenizer configuration\n",
    "    \n",
    "    # File paths\n",
    "    train_file = \"train.jsonl\"\n",
    "    test_file = \"test.jsonl\"\n",
    "    tokenizer_training_file = \"train.jsonl\"\n",
    "    \n",
    "    if not os.path.exists(train_file) or not os.path.exists(test_file):\n",
    "        raise FileNotFoundError(\"train.jsonl and/or test.jsonl not found.\")\n",
    "    \n",
    "    # Prepare the SentencePiece tokenizer\n",
    "    sp = train_tokenizer_if_needed(tokenizer_model_prefix=\"tokenizer\", vocab_size=vocab_size, training_text_file=tokenizer_training_file)\n",
    "    pad_token_id = sp.pad_id()\n",
    "    print(\"Pad Token ID:\", pad_token_id)\n",
    "    \n",
    "    # Load and tokenize the data\n",
    "    train_tokens = load_and_tokenize(train_file, sp)\n",
    "    val_tokens = load_and_tokenize(test_file, sp)\n",
    "    \n",
    "    # Build fixed-length sequences\n",
    "    train_seqs = build_sequences(train_tokens, max_seq_length)\n",
    "    val_seqs = build_sequences(val_tokens, max_seq_length)\n",
    "    \n",
    "    # Create Dataset objects and DataLoaders\n",
    "    train_dataset = LanguageModelDataset(train_seqs, max_seq_length)\n",
    "    val_dataset = LanguageModelDataset(val_seqs, max_seq_length)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # Initialize all three models in a dictionary for easy looping.\n",
    "    models = {\n",
    "        \"RNN\": RNNLanguageModel(vocab_size, embed_dim, hidden_dim, num_layers, dropout=dropout_rate),\n",
    "        \"LSTM\": LSTMLanguageModel(vocab_size, embed_dim, hidden_dim, num_layers, dropout=dropout_rate),\n",
    "        \"Transformer\": TransformerLanguageModel(vocab_size, embed_dim, num_heads, hidden_dim, num_layers, max_seq_length, dropout=dropout_rate)\n",
    "    }\n",
    "    \n",
    "    model_results = {}\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n--- Training {name} Model ---\")\n",
    "        model.to(device)\n",
    "        criterion = nn.CrossEntropyLoss(ignore_index=pad_token_id)\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, threshold=1e-4, verbose=True)\n",
    "        \n",
    "        start_model = time.time()\n",
    "        train_losses, val_losses = train_model(model, train_loader, val_loader, num_epochs,\n",
    "                                                criterion, optimizer, scheduler, device, pad_token_id, patience=3)\n",
    "        training_time = time.time() - start_model\n",
    "        plot_loss_curve(train_losses, val_losses, name)\n",
    "        val_loss = evaluate_model(model, val_loader, criterion, device, pad_token_id)\n",
    "        perplexity = math.exp(val_loss)\n",
    "        print(f\"{name} Model | Perplexity: {perplexity:.2f}, Training Time: {training_time:.2f}s\")\n",
    "        \n",
    "        # Save model parameters\n",
    "        torch.save(model.state_dict(), f\"{name}_model.pt\")\n",
    "        print(f\"{name} model saved as {name}_model.pt\")\n",
    "        \n",
    "        # Generate sample text for a fixed prompt.\n",
    "        fixed_prompt = \"Which do you prefer? Dogs or cats?\"\n",
    "        sample_output = model.prompt(sp, fixed_prompt, max_length=128, temperature=1.0, pad_token_id=pad_token_id)\n",
    "        print(f\"Sample output for {name} model:\", sample_output)\n",
    "        \n",
    "        model_results[name] = {\n",
    "            \"Perplexity\": perplexity,\n",
    "            \"TrainingTime\": training_time\n",
    "        }\n",
    "    \n",
    "    print(\"\\n--- Model Performance Summary ---\")\n",
    "    for model_name, metrics in model_results.items():\n",
    "        print(f\"{model_name}: Perplexity = {metrics['Perplexity']:.2f}, Training Time = {metrics['TrainingTime']:.2f}s\")\n",
    "    total_time = time.time() - global_start\n",
    "    print(f\"\\nTotal elapsed time: {total_time:.2f} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
